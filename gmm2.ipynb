{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'data_tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-8064cc6cc806>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m                      loss='ELBO')\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-8064cc6cc806>\u001b[0m in \u001b[0;36mmake_data\u001b[0;34m(n_data)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Use TensorDataset, but only make use of the 'data_tensor' param.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     return DataLoader(TensorDataset(data_tensor=x, target_tensor=x),\n\u001b[0m\u001b[1;32m     17\u001b[0m         batch_size=n_data, shuffle=True)\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'data_tensor'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pyro\n",
    "import pyro.infer\n",
    "import pyro.optim\n",
    "import pyro.distributions as dist\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "def make_data(n_data=1000):\n",
    "    \"\"\" Sample n_data datapoints from a 1-d mixture of Gaussians. \"\"\"\n",
    "    p = [.5, .5]\n",
    "    means = np.random.choice([-2, 4], n_data, p=p)\n",
    "    x = torch.Tensor(np.random.randn(n_data) + means).view(n_data, 1)\n",
    "    # Use TensorDataset, but only make use of the 'data_tensor' param.\n",
    "    return DataLoader(TensorDataset(data_tensor=x, target_tensor=x),\n",
    "        batch_size=n_data, shuffle=True)\n",
    "\n",
    "def model(data):\n",
    "    x = Variable(data[0]).squeeze()\n",
    "    n_data = x.size()[0]\n",
    "\n",
    "    # Define p_{theta}(z).\n",
    "    mu = pyro.param('mu', Variable(torch.Tensor([-2, 4]), requires_grad=True))\n",
    "    sigma = Variable(torch.ones(n_data)) # Constant variances.\n",
    "    ps = Variable(torch.Tensor([.5, .5])) # Constant component probabilities.\n",
    "    zs = pyro.sample('zs', dist.categorical, ps, batch_size=n_data)\n",
    "\n",
    "    # Define p_{theta}(x | z).\n",
    "    comp_ids = torch.max(zs, 1)[1] # Choose a component for each datapoint.\n",
    "    mus = mu[comp_ids] # Assign the appropriate mean to each datapoint.\n",
    "    pyro.observe('obs', dist.normal, x, mus, sigma) # Condition on data.\n",
    "\n",
    "    return mu.data.numpy() # We will monitor mu as training progresses.\n",
    "\n",
    "def guide(data):\n",
    "    n_data = data[0].size()[0]\n",
    "\n",
    "    # Sample q(z) from a categorical distribution.\n",
    "    ps = Variable(torch.Tensor([.5, .5]))\n",
    "    pyro.sample('zs', dist.categorical, ps, batch_size=n_data)\n",
    "\n",
    "\n",
    "svi = pyro.infer.SVI(model=model,\n",
    "                     guide=guide,\n",
    "                     optim=pyro.optim.Adam({'lr': 0.1}),\n",
    "                     loss='ELBO')\n",
    "\n",
    "dataloader = make_data()\n",
    "for t in range(100):\n",
    "    losses = []\n",
    "    for batch in dataloader:\n",
    "        losses.append(svi.step(batch))\n",
    "    mus = model(batch)\n",
    "    print('err={}. mus={}'.format(np.mean(losses), mus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
