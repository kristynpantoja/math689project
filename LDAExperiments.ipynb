{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "import TopicVAE\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import argparse\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec, FastText, KeyedVectors\n",
    "from os.path import isfile\n",
    "\n",
    "import tools\n",
    "\n",
    "import random\n",
    "random.seed(1234)\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data (20NewsGroups) and make the doc-term matrix, which is the input to all of our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words = 'english', min_df=.01, max_df=0.9, \n",
    "                             token_pattern = u'(?ui)\\\\b[a-z]{3,}\\\\b')\n",
    "count_vecs = vectorizer.fit_transform(newsgroups_train.data)\n",
    "doc_term_matrix = count_vecs.toarray()\n",
    "doc_term_matrix.shape # number of documents, number of words (in vocab)\n",
    "\n",
    "# note: vectorizer.get_feature_names() != vectorizer.vocabulary_\n",
    "\n",
    "doc_term_matrix_tensor = torch.from_numpy(doc_term_matrix).float()\n",
    "\n",
    "args_dict = {\"en1_units\" : 100, \"en2_units\" : 100, \"num_topic\" : 50, \n",
    "             \"batch_size\" : 200, \"optimizer\" : 80, \"learning_rate\" : 0.002, \n",
    "             \"momentum\" : 0.99, \"num_epoch\" : 80, \"init_mult\" : 1, \n",
    "             \"variance\" : 0.995, \"start\" : True, \"nogpu\" : True, \n",
    "             \"embedding_dim\" : 300, \"freeze\" : False}\n",
    "args = SimpleNamespace(**args_dict)\n",
    "args.num_input = doc_term_matrix_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "\n",
    "count_vecs_test = vectorizer.transform(newsgroups_test.data)\n",
    "doc_term_matrix_test = count_vecs_test.toarray()\n",
    "\n",
    "# note: vectorizer.get_feature_names() != vectorizer.vocabulary_\n",
    "\n",
    "doc_term_tensor_test = torch.from_numpy(doc_term_matrix_test).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Pretrained Vectors (20NewsGroups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make input to language models (word2vec, fasttext, etc.) ###\n",
    "\n",
    "# we would do some more preprocessing later\n",
    "newsgroups_train_preproc = []\n",
    "for document in newsgroups_train.data:\n",
    "    newsgroups_train_preproc.append(document.split())\n",
    "    \n",
    "# dict_word_freq = dict(zip(vectorizer.get_feature_names(), list(doc_term_matrix.sum(0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec: Skip-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make language model using word2vec ###\n",
    "\n",
    "w2v = Word2Vec(sg=1, negative=5, size=300, window=10, min_count=1, max_vocab_size=None, seed=1, workers=1)\n",
    "lm_w2v_20newsgroups = tools.create_language_model(\"lm_w2v_20newsgroups\", w2v, doc_term_matrix,\n",
    "                                            vectorizer.get_feature_names(), \n",
    "                                            sentences = newsgroups_train_preproc)\n",
    "\n",
    "### get embedding matrix for word2vec language model trained on 20newsgroups ###\n",
    "embedding_matrix_w2v_20newsgroups = tools.create_embedding_matrix(lm_w2v_20newsgroups, \n",
    "                                                                  vectorizer.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText: Skip-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext = FastText(sg=1, negative=5,size=300, window=10, min_count=1, max_vocab_size=None, seed=1, workers=1)\n",
    "lm_fasttext_20newsgroups = tools.create_language_model(\"lm_fasttext_20newsgroups\", fasttext, doc_term_matrix,\n",
    "                                                       vectorizer.get_feature_names(), \n",
    "                                                       sentences = newsgroups_train_preproc)\n",
    "\n",
    "### get embedding matrix for word2vec language model trained on 20newsgroups ###\n",
    "embedding_matrix_fasttext_20newsgroups = tools.create_embedding_matrix(lm_fasttext_20newsgroups, \n",
    "                                                                       vectorizer.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec: CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make language model using word2vec ###\n",
    "\n",
    "w2v_cbow = Word2Vec(sg=0, negative=5, size=300, window=10, min_count=1, max_vocab_size=None, seed=1, workers=1)\n",
    "lm_w2v_cbow_20newsgroups = tools.create_language_model(\"lm_w2v_cbow_20newsgroups\", w2v_cbow, doc_term_matrix,\n",
    "                                                       vectorizer.get_feature_names(), sentences = newsgroups_train_preproc)\n",
    "\n",
    "### get embedding matrix for word2vec language model trained on 20newsgroups ###\n",
    "embedding_matrix_w2v_cbow_20newsgroups = tools.create_embedding_matrix(lm_w2v_cbow_20newsgroups, \n",
    "                                                                  vectorizer.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText: CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_cbow = FastText(sg=0, negative=5,size=300, window=10, min_count=1, max_vocab_size=None, seed=1, workers=1)\n",
    "lm_fasttext_cbow_20newsgroups = tools.create_language_model(\"lm_fasttext_cbow_20newsgroups\", fasttext_cbow,\n",
    "                                                            doc_term_matrix, vectorizer.get_feature_names(), \n",
    "                                                            sentences = newsgroups_train_preproc)\n",
    "\n",
    "### get embedding matrix for word2vec language model trained on 20newsgroups ###\n",
    "embedding_matrix_fasttext_cbow_20newsgroups = tools.create_embedding_matrix(lm_fasttext_cbow_20newsgroups, \n",
    "                                                                       vectorizer.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Pretrained Vectors (trained on outside)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText: from Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained_language_model = api.load(\"fasttext-wiki-news-subwords-300\")\n",
    "# pretrained_language_model.save(\"fasttext-wiki-news-subwords-300\")\n",
    "\n",
    "lm_fasttext_wiki = KeyedVectors.load(\"fasttext-wiki-news-subwords-300\")\n",
    "\n",
    "embedding_matrix_fasttext_wiki = np.random.randn(len(vectorizer.get_feature_names()), 300)\n",
    "iterator = 0\n",
    "for word in vectorizer.get_feature_names():\n",
    "    if word in lm_fasttext_wiki.wv.vocab:\n",
    "        embedding_matrix_fasttext_wiki[iterator] = lm_fasttext_wiki.wv.word_vec(word)\n",
    "    else:\n",
    "        continue\n",
    "        # embedding_matrix2[iterator] = pretrained_language_model.wv.most_similar(word)\n",
    "        # or something like that\n",
    "    iterator += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec: from ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't actually the method described in Miao et. al., since the encoder is different (it's not MLP) - however, the decoder is (I think) the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_matrix_fasttext_20newsgroups' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-bf3e1692fa23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1234\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mGSMLDA_w2v_20news\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTopicVAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGSMLDA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_matrix_w2v_20newsgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mGSMLDA_fasttext_20news\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTopicVAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGSMLDA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_matrix_fasttext_20newsgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mGSMLDA_w2v_cbow_20news\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTopicVAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGSMLDA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_matrix_w2v_cbow_20newsgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mGSMLDA_fasttext_cbow_20news\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTopicVAE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGSMLDA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_matrix_fasttext_cbow_20newsgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'embedding_matrix_fasttext_20newsgroups' is not defined"
     ]
    }
   ],
   "source": [
    "#### Want several models\n",
    "\n",
    "n = 5\n",
    "\n",
    "GSMLDA_w2v_20news = []\n",
    "GSMLDA_fasttext_20news = []\n",
    "GSMLDA_w2v_cbow_20news = []\n",
    "GSMLDA_fasttext_cbow_20news = []\n",
    "GSMLDA_fasttext_wiki = []\n",
    "GSMLDA = []\n",
    "NVLDA = []\n",
    "\n",
    "\n",
    "for i in range(n):\n",
    "    random.seed(1234 + i)\n",
    "    GSMLDA_w2v_20news = TopicVAE.GSMLDA(args, embedding_matrix_w2v_20newsgroups)\n",
    "    GSMLDA_fasttext_20news = TopicVAE.GSMLDA(args, embedding_matrix_fasttext_20newsgroups)\n",
    "    GSMLDA_w2v_cbow_20news = TopicVAE.GSMLDA(args, embedding_matrix_w2v_cbow_20newsgroups)\n",
    "    GSMLDA_fasttext_cbow_20news = TopicVAE.GSMLDA(args, embedding_matrix_fasttext_cbow_20newsgroups)\n",
    "    GSMLDA_fasttext_wiki = TopicVAE.GSMLDA(args, embedding_matrix_fasttext_wiki)\n",
    "    GSMLDA = TopicVAE.GSMLDA(args)\n",
    "    NVLDA = TopicVAE.LDA(args)\n",
    "    \n",
    "    GSMLDA_w2v_20news.append(tools.create_TopicVAE_model(\"GSMLDA_w2v_20news_\" + str(i), \n",
    "                                                         GSMLDA_w2v_20news, args, doc_term_matrix_tensor))\n",
    "    GSMLDA_fasttext_20news.append(tools.create_TopicVAE_model(\"GSMLDA_fasttext_20news_\" + str(i), \n",
    "                                                              GSMLDA_fasttext_20news, args, doc_term_matrix_tensor))\n",
    "    GSMLDA_w2v_cbow_20news.append(tools.create_TopicVAE_model(\"GSMLDA_w2v_cbow_20news_\" + str(i), \n",
    "                                                              GSMLDA_w2v_cbow_20news, args, doc_term_matrix_tensor))\n",
    "    GSMLDA_fasttext_cbow_20news.append(tools.create_TopicVAE_model(\"GSMLDA_fasttext_cbow_20news_\" + str(i), \n",
    "                                                                   GSMLDA_fasttext_cbow_20news, args, doc_term_matrix_tensor))\n",
    "    GSMLDA_fasttext_wiki.append(tools.create_TopicVAE_model(\"GSMLDA_fasttext_wiki_\" + str(i), \n",
    "                                                            GSMLDA_fasttext_wiki, args, doc_term_matrix_tensor))\n",
    "    GSMLDA.append(tools.create_TopicVAE_model(\"GSMLDA\" + str(i), GSMLDA, args, doc_term_matrix_tensor))\n",
    "    NVLDA.append(tools.create_TopicVAE_model(\"NVLDA\" + str(i), NVLDA, args, doc_term_matrix_tensor))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText: Skip-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isfile(\"model_GSMLDA_fasttext_20news\"):\n",
    "    model_GSMLDA_fasttext_20news = torch.load(\"model_GSMLDA_fasttext_20news\")\n",
    "else:\n",
    "    model_GSMLDA_fasttext_20news = TopicVAE.GSMLDA(args, embedding_matrix_fasttext_20newsgroups)\n",
    "    optimizer_GSMLDA_fasttext_20news = torch.optim.Adam(model_GSMLDA_fasttext_20news.parameters(), args.learning_rate, \n",
    "                                            betas=(args.momentum, 0.999))\n",
    "    model_GSMLDA_fasttext_20news = TopicVAE.train(model_GSMLDA_fasttext_20news, args, optimizer_GSMLDA_fasttext_20news, \n",
    "                                             doc_term_matrix_tensor)\n",
    "    torch.save(model_GSMLDA_fasttext_20news, \"model_GSMLDA_fasttext_20news\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec: CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isfile(\"model_GSMLDA_w2v_cbow_20news\"):\n",
    "    model_GSMLDA_w2v_cbow_20news = torch.load(\"model_GSMLDA_w2v_cbow_20news\")\n",
    "else:\n",
    "    model_GSMLDA_w2v_cbow_20news = TopicVAE.GSMLDA(args, embedding_matrix_w2v_cbow_20newsgroups)\n",
    "    optimizer_GSMLDA_w2v_cbow_20news = torch.optim.Adam(model_GSMLDA_w2v_cbow_20news.parameters(), args.learning_rate, \n",
    "                                            betas=(args.momentum, 0.999))\n",
    "    model_GSMLDA_w2v_cbow_20news = TopicVAE.train(model_GSMLDA_w2v_cbow_20news, args, optimizer_GSMLDA_w2v_cbow_20news, \n",
    "                                             doc_term_matrix_tensor)\n",
    "    torch.save(model_GSMLDA_w2v_cbow_20news, \"model_GSMLDA_w2v_cbow_20news\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText: CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isfile(\"model_GSMLDA_fasttext_cbow_20news\"):\n",
    "    model_GSMLDA_fasttext_cbow_20news = torch.load(\"model_GSMLDA_fasttext_cbow_20news\")\n",
    "else:\n",
    "    model_GSMLDA_fasttext_cbow_20news = TopicVAE.GSMLDA(args, embedding_matrix_fasttext_cbow_20newsgroups)\n",
    "    optimizer_GSMLDA_fasttext_cbow_20news = torch.optim.Adam(model_GSMLDA_fasttext_cbow_20news.parameters(), args.learning_rate, \n",
    "                                            betas=(args.momentum, 0.999))\n",
    "    model_GSMLDA_fasttext_cbow_20news = TopicVAE.train(model_GSMLDA_fasttext_cbow_20news, args, optimizer_GSMLDA_fasttext_cbow_20news, \n",
    "                                             doc_term_matrix_tensor)\n",
    "    torch.save(model_GSMLDA_fasttext_cbow_20news, \"model_GSMLDA_fasttext_cbow_20news\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miao with Pretrained Vectors (outside text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText: from Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isfile(\"model_GSMLDA_fasttext_wiki\"):\n",
    "    model_GSMLDA_fasttext_wiki = torch.load(\"model_GSMLDA_fasttext_wiki\")\n",
    "else:\n",
    "    model_GSMLDA_fasttext_wiki = TopicVAE.GSMLDA(args, embedding_matrix_fasttext_wiki)\n",
    "    optimizer_GSMLDA_fasttext_wiki = torch.optim.Adam(model_GSMLDA_fasttext_wiki.parameters(), args.learning_rate, \n",
    "                                            betas=(args.momentum, 0.999))\n",
    "    model_GSMLDA_fasttext_wiki = TopicVAE.train(model_GSMLDA_fasttext_wiki, args, optimizer_GSMLDA_fasttext_wiki, \n",
    "                                             doc_term_matrix_tensor)\n",
    "    torch.save(model_GSMLDA_fasttext_wiki, \"model_GSMLDA_fasttext_wiki\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSMLDA_fasttext_wiki_coherences = tools.topic_coherence(model_GSMLDA_fasttext_wiki.get_beta(),\n",
    "                                                        20, doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSMLDA_fasttext_wiki_coherences_mean = GSMLDA_fasttext_wiki_coherences.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(GSMLDA_fasttext_wiki_coherences_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec: from ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miao without Pretrained Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isfile(\"model_GSMLDA\"):\n",
    "    model_GSMLDA = torch.load(\"model_GSMLDA\")\n",
    "else:\n",
    "    model_GSMLDA = TopicVAE.GSMLDA(args)\n",
    "    optimizer_GSMLDA = torch.optim.Adam(model_GSMLDA.parameters(), args.learning_rate, betas=(args.momentum, 0.999))\n",
    "    model_GSMLDA = TopicVAE.train(model_GSMLDA, args, optimizer_GSMLDA, doc_term_matrix_tensor)\n",
    "    torch.save(model_GSMLDA, \"model_GSMLDA\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSMLDA_coherences = tools.topic_coherence(model_GSMLDA.get_beta(), 20, doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSMLDA_coherences_mean = GSMLDA_coherences.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(GSMLDA_coherences_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isfile(\"model_GSMLDA2\"):\n",
    "    model_GSMLDA2 = torch.load(\"model_GSMLDA2\")\n",
    "else:\n",
    "    model_GSMLDA2 = TopicVAE.GSMLDA(args)\n",
    "    optimizer_GSMLDA2 = torch.optim.Adam(model_GSMLDA2.parameters(), args.learning_rate, betas=(args.momentum, 0.999))\n",
    "    model_GSMLDA2 = TopicVAE.train(model_GSMLDA2, args, optimizer_GSMLDA2, doc_term_matrix_tensor)\n",
    "    torch.save(model_GSMLDA2, \"model_GSMLDA2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSMLDA2_coherences = tools.topic_coherence(model_GSMLDA2.get_beta(), 20, doc_term_matrix)\n",
    "GSMLDA2_coherences_mean = GSMLDA2_coherences.mean()\n",
    "print(GSMLDA2_coherences_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NVLDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isfile(\"model_LDA\"):\n",
    "    model_LDA = torch.load(\"model_LDA\")\n",
    "else:\n",
    "    model_LDA = TopicVAE.LDA(args)\n",
    "    optimizer_LDA = torch.optim.Adam(model_LDA.parameters(), args.learning_rate, betas=(args.momentum, 0.999))\n",
    "    model_GSMLDA = TopicVAE.train(model_LDA, args, optimizer_LDA, doc_term_matrix_tensor)\n",
    "    torch.save(model_LDA, \"model_LDA\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Coherences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_GSMLDA_w2v_20news_beta = model_GSMLDA_w2v_20news.get_beta()\n",
    "# tools.print_top_words(model_GSMLDA_w2v_20news_beta, vectorizer.get_feature_names(), n_top_words = 20)\n",
    "\n",
    "models = [model_GSMLDA_w2v_20news, model_GSMLDA_fasttext_20news, \n",
    "          model_GSMLDA_w2v_cbow_20news, model_GSMLDA_fasttext_cbow_20news, \n",
    "          model_GSMLDA_fasttext_wiki, model_GSMLDA, model_LDA]\n",
    "\n",
    "models_betas = [model.get_beta() for model in models]\n",
    "coherences = [tools.topic_coherence(beta, 20, doc_term_matrix) for beta in models_betas]\n",
    "coherences_means = [coherences.mean() for coherences in coherences]\n",
    "coherences_means_df = pd.DataFrame(coherences_means).to_latex()\n",
    "\n",
    "print(coherences_means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.topic_coherence(model_LDA.get_beta(), 20, doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.print_top_words(model_GSMLDA2.get_beta(), vectorizer.get_feature_names(), n_top_words = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Perplexities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.perplexity(model_GSMLDA, doc_term_tensor_test)\n",
    "\n",
    "perplexities = [tools.perplexity(model, doc_term_tensor_test).item() for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(perplexities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Coherences OLD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.style.use(\"seaborn-deep\")\n",
    "\n",
    "x = GSMLDA_without_embedding_coherence\n",
    "y = GSMLDA2_20newsgroups_coherence\n",
    "\n",
    "plt.hist([x, y], label = [\"without embedding\", \"with 20newsgroups embedding\"])\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.show()\n",
    "\n",
    "# t test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_word_vecs = dict(zip(vectorizer.get_feature_names(), [model_GSMLDA2.word_embedding.weight[i] for i in range(model_GSMLDA2.word_embedding.weight.shape[0])]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GSMLDA2.word_embedding.weight.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([model_GSMLDA2.word_embedding.weight[i] for i in range(model_GSMLDA2.word_embedding.weight.shape[0])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_matrix = cosine_similarity(model_GSMLDA2.word_embedding.weight.detach().numpy(), \n",
    "                                   model_GSMLDA2.word_embedding.weight.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_closest_words(word, cos_sim_matrix, n):\n",
    "    word_index = vectorizer.get_feature_names().index(word)\n",
    "    close_words_indices = np.argsort(cos_sim_matrix[word_index])[-n:]\n",
    "    print(close_words_indices)\n",
    "    return [vectorizer.get_feature_names()[j] for j in close_words_indices]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_closest_words(\"nasa\", cos_sim_matrix, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GSMLDA_cos_sim_matrix = cosine_similarity(model_GSMLDA_without_embedding.word_embedding.weight.detach().numpy(), \n",
    "                                   model_GSMLDA_without_embedding.word_embedding.weight.detach().numpy())\n",
    "n_closest_words(\"amendment\", model_GSMLDA_cos_sim_matrix, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_20newsgroups.most_similar(\"nasa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.perplexity(model_GSMLDA, doc_term_tensor_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_tensor_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_matrix_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_matrix_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:math689env]",
   "language": "python",
   "name": "conda-env-math689env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
