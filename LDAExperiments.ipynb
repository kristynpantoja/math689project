{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "import TopicVAE\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import argparse\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec, FastText, KeyedVectors\n",
    "from os.path import isfile\n",
    "\n",
    "import tools\n",
    "\n",
    "import random\n",
    "random.seed(1234)\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data (20NewsGroups) and make the doc-term matrix, which is the input to all of our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words = 'english', min_df=.01, max_df=0.9, \n",
    "                             token_pattern = u'(?ui)\\\\b[a-z]{3,}\\\\b')\n",
    "count_vecs = vectorizer.fit_transform(newsgroups_train.data)\n",
    "doc_term_matrix = count_vecs.toarray()\n",
    "doc_term_matrix.shape # number of documents, number of words (in vocab)\n",
    "\n",
    "# note: vectorizer.get_feature_names() != vectorizer.vocabulary_\n",
    "\n",
    "doc_term_matrix_tensor = torch.from_numpy(doc_term_matrix).float()\n",
    "\n",
    "args_dict = {\"en1_units\" : 100, \"en2_units\" : 100, \"num_topic\" : 50, \n",
    "             \"batch_size\" : 200, \"optimizer\" : 80, \"learning_rate\" : 0.002, \n",
    "             \"momentum\" : 0.99, \"num_epoch\" : 80, \"init_mult\" : 1, \n",
    "             \"variance\" : 0.995, \"start\" : True, \"nogpu\" : True, \n",
    "             \"embedding_dim\" : 300, \"freeze\" : False}\n",
    "args = SimpleNamespace(**args_dict)\n",
    "args.num_input = doc_term_matrix_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "\n",
    "count_vecs_test = vectorizer.transform(newsgroups_test.data)\n",
    "doc_term_matrix_test = count_vecs_test.toarray()\n",
    "\n",
    "# note: vectorizer.get_feature_names() != vectorizer.vocabulary_\n",
    "\n",
    "doc_term_tensor_test = torch.from_numpy(doc_term_matrix_test).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Pretrained Vectors (20NewsGroups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make input to language models (word2vec, fasttext, etc.) ###\n",
    "\n",
    "# we would do some more preprocessing later\n",
    "newsgroups_train_preproc = []\n",
    "for document in newsgroups_train.data:\n",
    "    newsgroups_train_preproc.append(document.split())\n",
    "    \n",
    "# dict_word_freq = dict(zip(vectorizer.get_feature_names(), list(doc_term_matrix.sum(0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec: Skip-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make language model using word2vec ###\n",
    "\n",
    "w2v = Word2Vec(sg=1, negative=5, size=300, window=10, min_count=1, max_vocab_size=None, seed=1, workers=1)\n",
    "lm_w2v_20newsgroups = tools.create_language_model(\"lm_w2v_20newsgroups\", w2v, doc_term_matrix,\n",
    "                                            vectorizer.get_feature_names(), \n",
    "                                            sentences = newsgroups_train_preproc)\n",
    "\n",
    "### get embedding matrix for word2vec language model trained on 20newsgroups ###\n",
    "embedding_matrix_w2v_20newsgroups = tools.create_embedding_matrix(lm_w2v_20newsgroups, \n",
    "                                                                  vectorizer.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText: Skip-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext = FastText(sg=1, negative=5,size=300, window=10, min_count=1, max_vocab_size=None, seed=1, workers=1)\n",
    "lm_fasttext_20newsgroups = tools.create_language_model(\"lm_fasttext_20newsgroups\", fasttext, doc_term_matrix,\n",
    "                                                       vectorizer.get_feature_names(), \n",
    "                                                       sentences = newsgroups_train_preproc)\n",
    "\n",
    "### get embedding matrix for word2vec language model trained on 20newsgroups ###\n",
    "embedding_matrix_fasttext_20newsgroups = tools.create_embedding_matrix(lm_fasttext_20newsgroups, \n",
    "                                                                       vectorizer.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec: CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make language model using word2vec ###\n",
    "\n",
    "w2v_cbow = Word2Vec(sg=0, negative=5, size=300, window=10, min_count=1, max_vocab_size=None, seed=1, workers=1)\n",
    "lm_w2v_cbow_20newsgroups = tools.create_language_model(\"lm_w2v_cbow_20newsgroups\", w2v_cbow, doc_term_matrix,\n",
    "                                                       vectorizer.get_feature_names(), sentences = newsgroups_train_preproc)\n",
    "\n",
    "### get embedding matrix for word2vec language model trained on 20newsgroups ###\n",
    "embedding_matrix_w2v_cbow_20newsgroups = tools.create_embedding_matrix(lm_w2v_cbow_20newsgroups, \n",
    "                                                                  vectorizer.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText: CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_cbow = FastText(sg=0, negative=5,size=300, window=10, min_count=1, max_vocab_size=None, seed=1, workers=1)\n",
    "lm_fasttext_cbow_20newsgroups = tools.create_language_model(\"lm_fasttext_cbow_20newsgroups\", fasttext_cbow,\n",
    "                                                            doc_term_matrix, vectorizer.get_feature_names(), \n",
    "                                                            sentences = newsgroups_train_preproc)\n",
    "\n",
    "### get embedding matrix for word2vec language model trained on 20newsgroups ###\n",
    "embedding_matrix_fasttext_cbow_20newsgroups = tools.create_embedding_matrix(lm_fasttext_cbow_20newsgroups, \n",
    "                                                                       vectorizer.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Pretrained Vectors (trained on outside)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText: from Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/math689env/lib/python3.7/site-packages/ipykernel/__main__.py:9: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "/anaconda3/envs/math689env/lib/python3.7/site-packages/ipykernel/__main__.py:10: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    }
   ],
   "source": [
    "# pretrained_language_model = api.load(\"fasttext-wiki-news-subwords-300\")\n",
    "# pretrained_language_model.save(\"fasttext-wiki-news-subwords-300\")\n",
    "\n",
    "lm_fasttext_wiki = KeyedVectors.load(\"fasttext-wiki-news-subwords-300\")\n",
    "\n",
    "embedding_matrix_fasttext_wiki = np.random.randn(len(vectorizer.get_feature_names()), 300)\n",
    "iterator = 0\n",
    "for word in vectorizer.get_feature_names():\n",
    "    if word in lm_fasttext_wiki.wv.vocab:\n",
    "        embedding_matrix_fasttext_wiki[iterator] = lm_fasttext_wiki.wv.word_vec(word)\n",
    "    else:\n",
    "        continue\n",
    "        # embedding_matrix2[iterator] = pretrained_language_model.wv.most_similar(word)\n",
    "        # or something like that\n",
    "    iterator += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec: from ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't actually the method described in Miao et. al., since the encoder is different (it's not MLP) - however, the decoder is (I think) the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Want several models\n",
    "\n",
    "n = 5\n",
    "\n",
    "GSMLDA_w2v_20news = []\n",
    "GSMLDA_fasttext_20news = []\n",
    "GSMLDA_w2v_cbow_20news = []\n",
    "GSMLDA_fasttext_cbow_20news = []\n",
    "GSMLDA_fasttext_wiki = []\n",
    "GSMLDA = []\n",
    "NVLDA = []\n",
    "\n",
    "\n",
    "for i in range(n):\n",
    "    random.seed(1234 + i)\n",
    "    GSMLDA_w2v_20news_model = TopicVAE.GSMLDA(args, embedding_matrix_w2v_20newsgroups)\n",
    "    GSMLDA_fasttext_20news_model = TopicVAE.GSMLDA(args, embedding_matrix_fasttext_20newsgroups)\n",
    "    GSMLDA_w2v_cbow_20news_model = TopicVAE.GSMLDA(args, embedding_matrix_w2v_cbow_20newsgroups)\n",
    "    GSMLDA_fasttext_cbow_20news_model = TopicVAE.GSMLDA(args, embedding_matrix_fasttext_cbow_20newsgroups)\n",
    "    GSMLDA_fasttext_wiki_model = TopicVAE.GSMLDA(args, embedding_matrix_fasttext_wiki)\n",
    "    GSMLDA_model = TopicVAE.GSMLDA(args)\n",
    "    NVLDA_model = TopicVAE.LDA(args)\n",
    "    \n",
    "    GSMLDA_w2v_20news.append(tools.create_TopicVAE_model(\"GSMLDA_w2v_20news_\" + str(i), \n",
    "                                                         GSMLDA_w2v_20news_model, args, doc_term_matrix_tensor))\n",
    "    GSMLDA_fasttext_20news.append(tools.create_TopicVAE_model(\"GSMLDA_fasttext_20news_\" + str(i), \n",
    "                                                              GSMLDA_fasttext_20news_model, args, doc_term_matrix_tensor))\n",
    "    GSMLDA_w2v_cbow_20news.append(tools.create_TopicVAE_model(\"GSMLDA_w2v_cbow_20news_\" + str(i), \n",
    "                                                              GSMLDA_w2v_cbow_20news_model, args, doc_term_matrix_tensor))\n",
    "    GSMLDA_fasttext_cbow_20news.append(tools.create_TopicVAE_model(\"GSMLDA_fasttext_cbow_20news_\" + str(i), \n",
    "                                                                   GSMLDA_fasttext_cbow_20news_model, args, doc_term_matrix_tensor))\n",
    "    GSMLDA_fasttext_wiki.append(tools.create_TopicVAE_model(\"GSMLDA_fasttext_wiki_\" + str(i), \n",
    "                                                            GSMLDA_fasttext_wiki_model, args, doc_term_matrix_tensor))\n",
    "    GSMLDA.append(tools.create_TopicVAE_model(\"GSMLDA\" + str(i), GSMLDA_model, args, doc_term_matrix_tensor))\n",
    "    NVLDA.append(tools.create_TopicVAE_model(\"NVLDA\" + str(i), NVLDA_model, args, doc_term_matrix_tensor))\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-6e1359c584dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcoherences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcoherences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopic_coherence_NPMI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_beta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_term_matrix\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msub_model\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-6e1359c584dd>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcoherences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcoherences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopic_coherence_NPMI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_beta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_term_matrix\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msub_model\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Python/math689project/tools.py\u001b[0m in \u001b[0;36mtopic_coherence_NPMI\u001b[0;34m(beta, M, doc_term_matrix)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mcombos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mind1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mif_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc_term_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0mif_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdoc_term_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0md_ind2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mif_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "models = [GSMLDA_w2v_20news, GSMLDA_fasttext_20news, GSMLDA_w2v_cbow_20news, \n",
    "          GSMLDA_fasttext_cbow_20news, GSMLDA_fasttext_wiki, GSMLDA, NVLDA]\n",
    "\n",
    "coherences = []\n",
    "for model in models:\n",
    "    coherences.append([tools.topic_coherence_NPMI(sub_model.get_beta(), 20, doc_term_matrix) for sub_model in model])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_means = [np.mean(coherence) for coherence in coherences]\n",
    "coherence_ses = [np.std(coherence)/np.sqrt(5) for coherence in coherences]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coherence_means)\n",
    "print(coherence_sds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Perplexities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristyn/Desktop/Python/math689project/TopicVAE.py:174: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  p = F.softmax(z)                                                # mixture probability\n",
      "/Users/kristyn/Desktop/Python/math689project/TopicVAE.py:147: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  p = F.softmax(z)                                                # mixture probability\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[868.49884, 870.25653, 871.25244, 875.3202, 2296132600.0, 892.83215, 911.44305]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "perplexities = []\n",
    "for model in models:\n",
    "    perplexities.append([tools.perplexity(sub_model, doc_term_tensor_test) for sub_model in model])\n",
    "    \n",
    "[np.mean(perplexity) for perplexity in perplexities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.6202070471342904,\n",
       " 1.5407734242771198,\n",
       " 1.0327445741654535,\n",
       " 1.7373556152569092,\n",
       " 1257643168.408669,\n",
       " 1.8429923067331657,\n",
       " 1.5674330569926398]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.std(perplexity)/np.sqrt(5) for perplexity in perplexities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexities = []\n",
    "for model in models:\n",
    "    perplexities.append([tools.perplexity(sub_model, doc_term_tensor_test) for sub_model in model])\n",
    "    \n",
    "[float(perplexity) for perplexity in perplexities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Coherences OLD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.style.use(\"seaborn-deep\")\n",
    "\n",
    "x = GSMLDA_without_embedding_coherence\n",
    "y = GSMLDA2_20newsgroups_coherence\n",
    "\n",
    "plt.hist([x, y], label = [\"without embedding\", \"with 20newsgroups embedding\"])\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.show()\n",
    "\n",
    "# t test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_word_vecs = dict(zip(vectorizer.get_feature_names(), [model_GSMLDA2.word_embedding.weight[i] for i in range(model_GSMLDA2.word_embedding.weight.shape[0])]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GSMLDA2.word_embedding.weight.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([model_GSMLDA2.word_embedding.weight[i] for i in range(model_GSMLDA2.word_embedding.weight.shape[0])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_matrix = cosine_similarity(model_GSMLDA2.word_embedding.weight.detach().numpy(), \n",
    "                                   model_GSMLDA2.word_embedding.weight.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_closest_words(word, cos_sim_matrix, n):\n",
    "    word_index = vectorizer.get_feature_names().index(word)\n",
    "    close_words_indices = np.argsort(cos_sim_matrix[word_index])[-n:]\n",
    "    print(close_words_indices)\n",
    "    return [vectorizer.get_feature_names()[j] for j in close_words_indices]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_closest_words(\"nasa\", cos_sim_matrix, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GSMLDA_cos_sim_matrix = cosine_similarity(model_GSMLDA_without_embedding.word_embedding.weight.detach().numpy(), \n",
    "                                   model_GSMLDA_without_embedding.word_embedding.weight.detach().numpy())\n",
    "n_closest_words(\"amendment\", model_GSMLDA_cos_sim_matrix, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_20newsgroups.most_similar(\"nasa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.perplexity(model_GSMLDA, doc_term_tensor_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_tensor_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_matrix_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_matrix_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
