{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "import TopicVAE\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import argparse\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec, FastText, KeyedVectors\n",
    "from os.path import isfile\n",
    "\n",
    "import tools\n",
    "\n",
    "import random\n",
    "random.seed(1234)\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data (20NewsGroups) and make the doc-term matrix, which is the input to all of our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words = 'english', min_df=.01, max_df=0.9, \n",
    "                             token_pattern = u'(?ui)\\\\b[a-z]{3,}\\\\b')\n",
    "count_vecs = vectorizer.fit_transform(newsgroups_train.data)\n",
    "doc_term_matrix = count_vecs.toarray()\n",
    "doc_term_matrix.shape # number of documents, number of words (in vocab)\n",
    "\n",
    "# note: vectorizer.get_feature_names() != vectorizer.vocabulary_\n",
    "\n",
    "doc_term_matrix_tensor = torch.from_numpy(doc_term_matrix).float()\n",
    "\n",
    "args_dict = {\"en1_units\" : 100, \"en2_units\" : 100, \"num_topic\" : 50, \n",
    "             \"batch_size\" : 200, \"optimizer\" : 80, \"learning_rate\" : 0.002, \n",
    "             \"momentum\" : 0.99, \"num_epoch\" : 80, \"init_mult\" : 1, \n",
    "             \"variance\" : 0.995, \"start\" : True, \"nogpu\" : True, \n",
    "             \"embedding_dim\" : 300, \"freeze\" : False}\n",
    "args = SimpleNamespace(**args_dict)\n",
    "args.num_input = doc_term_matrix_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_test = fetch_20newsgroups(subset='test')\n",
    "\n",
    "count_vecs_test = vectorizer.transform(newsgroups_test.data)\n",
    "doc_term_matrix_test = count_vecs_test.toarray()\n",
    "\n",
    "# note: vectorizer.get_feature_names() != vectorizer.vocabulary_\n",
    "\n",
    "doc_term_tensor_test = torch.from_numpy(doc_term_matrix_test).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Pretrained Vectors (20NewsGroups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make input to language models (word2vec, fasttext, etc.) ###\n",
    "\n",
    "# we would do some more preprocessing later\n",
    "newsgroups_train_preproc = []\n",
    "for document in newsgroups_train.data:\n",
    "    newsgroups_train_preproc.append(document.split())\n",
    "    \n",
    "# dict_word_freq = dict(zip(vectorizer.get_feature_names(), list(doc_term_matrix.sum(0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec: Skip-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make language model using word2vec ###\n",
    "\n",
    "w2v = Word2Vec(sg=1, negative=5, size=300, window=10, min_count=1, max_vocab_size=None, seed=1, workers=1)\n",
    "lm_w2v_20newsgroups = tools.create_language_model(\"lm_w2v_20newsgroups\", w2v, doc_term_matrix,\n",
    "                                            vectorizer.get_feature_names(), \n",
    "                                            sentences = newsgroups_train_preproc)\n",
    "\n",
    "### get embedding matrix for word2vec language model trained on 20newsgroups ###\n",
    "embedding_matrix_w2v_20newsgroups = tools.create_embedding_matrix(lm_w2v_20newsgroups, \n",
    "                                                                  vectorizer.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText: Skip-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext = FastText(sg=1, negative=5,size=300, window=10, min_count=1, max_vocab_size=None, seed=1, workers=1)\n",
    "lm_fasttext_20newsgroups = tools.create_language_model(\"lm_fasttext_20newsgroups\", fasttext, doc_term_matrix,\n",
    "                                                       vectorizer.get_feature_names(), \n",
    "                                                       sentences = newsgroups_train_preproc)\n",
    "\n",
    "### get embedding matrix for word2vec language model trained on 20newsgroups ###\n",
    "embedding_matrix_fasttext_20newsgroups = tools.create_embedding_matrix(lm_fasttext_20newsgroups, \n",
    "                                                                       vectorizer.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec: CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make language model using word2vec ###\n",
    "\n",
    "w2v_cbow = Word2Vec(sg=0, negative=5, size=300, window=10, min_count=1, max_vocab_size=None, seed=1, workers=1)\n",
    "lm_w2v_cbow_20newsgroups = tools.create_language_model(\"lm_w2v_cbow_20newsgroups\", w2v_cbow, doc_term_matrix,\n",
    "                                                       vectorizer.get_feature_names(), sentences = newsgroups_train_preproc)\n",
    "\n",
    "### get embedding matrix for word2vec language model trained on 20newsgroups ###\n",
    "embedding_matrix_w2v_cbow_20newsgroups = tools.create_embedding_matrix(lm_w2v_cbow_20newsgroups, \n",
    "                                                                  vectorizer.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText: CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_cbow = FastText(sg=0, negative=5,size=300, window=10, min_count=1, max_vocab_size=None, seed=1, workers=1)\n",
    "lm_fasttext_cbow_20newsgroups = tools.create_language_model(\"lm_fasttext_cbow_20newsgroups\", fasttext_cbow,\n",
    "                                                            doc_term_matrix, vectorizer.get_feature_names(), \n",
    "                                                            sentences = newsgroups_train_preproc)\n",
    "\n",
    "### get embedding matrix for word2vec language model trained on 20newsgroups ###\n",
    "embedding_matrix_fasttext_cbow_20newsgroups = tools.create_embedding_matrix(lm_fasttext_cbow_20newsgroups, \n",
    "                                                                       vectorizer.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Pretrained Vectors (trained on outside)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText: from Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/math689env/lib/python3.7/site-packages/ipykernel/__main__.py:9: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "/anaconda3/envs/math689env/lib/python3.7/site-packages/ipykernel/__main__.py:10: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    }
   ],
   "source": [
    "# pretrained_language_model = api.load(\"fasttext-wiki-news-subwords-300\")\n",
    "# pretrained_language_model.save(\"fasttext-wiki-news-subwords-300\")\n",
    "\n",
    "lm_fasttext_wiki = KeyedVectors.load(\"fasttext-wiki-news-subwords-300\")\n",
    "\n",
    "embedding_matrix_fasttext_wiki = np.random.randn(len(vectorizer.get_feature_names()), 300)\n",
    "iterator = 0\n",
    "for word in vectorizer.get_feature_names():\n",
    "    if word in lm_fasttext_wiki.wv.vocab:\n",
    "        embedding_matrix_fasttext_wiki[iterator] = lm_fasttext_wiki.wv.word_vec(word)\n",
    "    else:\n",
    "        continue\n",
    "        # embedding_matrix2[iterator] = pretrained_language_model.wv.most_similar(word)\n",
    "        # or something like that\n",
    "    iterator += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec: from ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Miao\" with Pretrained Vectors (on 20NewsGroups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't actually the method described in Miao et. al., since the encoder is different (it's not MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec: Skip-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristyn/Desktop/Python/math689project/TopicVAE.py:169: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  p = F.softmax(z)                                                # mixture probability\n",
      "/Users/kristyn/Desktop/Python/math689project/TopicVAE.py:111: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  loss_epoch += loss.data[0]    # add loss to loss_epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss=707.623779296875\n",
      "Epoch 5, loss=570.6974487304688\n",
      "Epoch 10, loss=561.2691650390625\n",
      "Epoch 15, loss=555.5097045898438\n",
      "Epoch 20, loss=551.9954833984375\n",
      "Epoch 25, loss=548.9158935546875\n",
      "Epoch 30, loss=547.31884765625\n",
      "Epoch 35, loss=545.2451782226562\n",
      "Epoch 40, loss=543.6106567382812\n",
      "Epoch 45, loss=541.9308471679688\n",
      "Epoch 50, loss=544.9839477539062\n",
      "Epoch 55, loss=542.3426513671875\n",
      "Epoch 60, loss=542.0008544921875\n",
      "Epoch 65, loss=543.2259521484375\n",
      "Epoch 70, loss=539.7322998046875\n",
      "Epoch 75, loss=540.2738037109375\n"
     ]
    }
   ],
   "source": [
    "if isfile(\"model_GSMLDA_w2v_20news\"):\n",
    "    model_GSMLDA_w2v_20news = torch.load(\"model_GSMLDA_w2v_20news\")\n",
    "else:\n",
    "    model_GSMLDA_w2v_20news = TopicVAE.GSMLDA(args, embedding_matrix_w2v_20newsgroups)\n",
    "    optimizer_GSMLDA_w2v_20news = torch.optim.Adam(model_GSMLDA_w2v_20news.parameters(), args.learning_rate, \n",
    "                                            betas=(args.momentum, 0.999))\n",
    "    model_GSMLDA_w2v_20news = TopicVAE.train(model_GSMLDA_w2v_20news, args, optimizer_GSMLDA_w2v_20news, \n",
    "                                             doc_term_matrix_tensor)\n",
    "    torch.save(model_GSMLDA_w2v_20news, \"model_GSMLDA_w2v_20news\")\n",
    "    \n",
    "    \n",
    "n = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText: Skip-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss=691.7111206054688\n",
      "Epoch 5, loss=570.8758544921875\n",
      "Epoch 10, loss=561.243896484375\n",
      "Epoch 15, loss=556.7259521484375\n",
      "Epoch 20, loss=552.0405883789062\n",
      "Epoch 25, loss=551.0697631835938\n",
      "Epoch 30, loss=548.2799682617188\n",
      "Epoch 35, loss=549.1189575195312\n",
      "Epoch 40, loss=546.4395751953125\n",
      "Epoch 45, loss=545.6307373046875\n",
      "Epoch 50, loss=542.1295776367188\n",
      "Epoch 55, loss=543.5731811523438\n",
      "Epoch 60, loss=543.1550903320312\n",
      "Epoch 65, loss=542.8093872070312\n",
      "Epoch 70, loss=542.3997802734375\n",
      "Epoch 75, loss=542.4989013671875\n"
     ]
    }
   ],
   "source": [
    "if isfile(\"model_GSMLDA_fasttext_20news\"):\n",
    "    model_GSMLDA_fasttext_20news = torch.load(\"model_GSMLDA_fasttext_20news\")\n",
    "else:\n",
    "    model_GSMLDA_fasttext_20news = TopicVAE.GSMLDA(args, embedding_matrix_fasttext_20newsgroups)\n",
    "    optimizer_GSMLDA_fasttext_20news = torch.optim.Adam(model_GSMLDA_fasttext_20news.parameters(), args.learning_rate, \n",
    "                                            betas=(args.momentum, 0.999))\n",
    "    model_GSMLDA_fasttext_20news = TopicVAE.train(model_GSMLDA_fasttext_20news, args, optimizer_GSMLDA_fasttext_20news, \n",
    "                                             doc_term_matrix_tensor)\n",
    "    torch.save(model_GSMLDA_fasttext_20news, \"model_GSMLDA_fasttext_20news\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec: CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss=761.8871459960938\n",
      "Epoch 5, loss=584.682373046875\n",
      "Epoch 10, loss=568.9644775390625\n",
      "Epoch 15, loss=562.3456420898438\n",
      "Epoch 20, loss=555.24853515625\n",
      "Epoch 25, loss=552.6206665039062\n",
      "Epoch 30, loss=551.4342041015625\n",
      "Epoch 35, loss=547.6995849609375\n",
      "Epoch 40, loss=546.9485473632812\n",
      "Epoch 45, loss=545.9097290039062\n",
      "Epoch 50, loss=543.5358276367188\n",
      "Epoch 55, loss=543.0621948242188\n",
      "Epoch 60, loss=540.9735717773438\n",
      "Epoch 65, loss=540.71826171875\n",
      "Epoch 70, loss=540.1134033203125\n",
      "Epoch 75, loss=540.0799560546875\n"
     ]
    }
   ],
   "source": [
    "if isfile(\"model_GSMLDA_w2v_cbow_20news\"):\n",
    "    model_GSMLDA_w2v_cbow_20news = torch.load(\"model_GSMLDA_w2v_cbow_20news\")\n",
    "else:\n",
    "    model_GSMLDA_w2v_cbow_20news = TopicVAE.GSMLDA(args, embedding_matrix_w2v_cbow_20newsgroups)\n",
    "    optimizer_GSMLDA_w2v_cbow_20news = torch.optim.Adam(model_GSMLDA_w2v_cbow_20news.parameters(), args.learning_rate, \n",
    "                                            betas=(args.momentum, 0.999))\n",
    "    model_GSMLDA_w2v_cbow_20news = TopicVAE.train(model_GSMLDA_w2v_cbow_20news, args, optimizer_GSMLDA_w2v_cbow_20news, \n",
    "                                             doc_term_matrix_tensor)\n",
    "    torch.save(model_GSMLDA_w2v_cbow_20news, \"model_GSMLDA_w2v_cbow_20news\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText: CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss=763.6353759765625\n",
      "Epoch 5, loss=585.0731811523438\n",
      "Epoch 10, loss=568.3031616210938\n",
      "Epoch 15, loss=561.2235717773438\n",
      "Epoch 20, loss=554.6532592773438\n",
      "Epoch 25, loss=554.6126098632812\n",
      "Epoch 30, loss=550.8827514648438\n",
      "Epoch 35, loss=548.2445068359375\n",
      "Epoch 40, loss=545.28955078125\n",
      "Epoch 45, loss=543.41162109375\n",
      "Epoch 50, loss=544.2401123046875\n",
      "Epoch 55, loss=542.5443115234375\n",
      "Epoch 60, loss=543.7285766601562\n",
      "Epoch 65, loss=541.4929809570312\n",
      "Epoch 70, loss=540.6140747070312\n",
      "Epoch 75, loss=539.5203247070312\n"
     ]
    }
   ],
   "source": [
    "if isfile(\"model_GSMLDA_fasttext_cbow_20news\"):\n",
    "    model_GSMLDA_fasttext_cbow_20news = torch.load(\"model_GSMLDA_fasttext_cbow_20news\")\n",
    "else:\n",
    "    model_GSMLDA_fasttext_cbow_20news = TopicVAE.GSMLDA(args, embedding_matrix_fasttext_cbow_20newsgroups)\n",
    "    optimizer_GSMLDA_fasttext_cbow_20news = torch.optim.Adam(model_GSMLDA_fasttext_cbow_20news.parameters(), args.learning_rate, \n",
    "                                            betas=(args.momentum, 0.999))\n",
    "    model_GSMLDA_fasttext_cbow_20news = TopicVAE.train(model_GSMLDA_fasttext_cbow_20news, args, optimizer_GSMLDA_fasttext_cbow_20news, \n",
    "                                             doc_term_matrix_tensor)\n",
    "    torch.save(model_GSMLDA_fasttext_cbow_20news, \"model_GSMLDA_fasttext_cbow_20news\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at Coherences, \"Miao\" Pretrained Vectors 20NewsGroups (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_GSMLDA_w2v_20news_beta = model_GSMLDA_w2v_20news.get_beta()\n",
    "# tools.print_top_words(model_GSMLDA_w2v_20news_beta, vectorizer.get_feature_names(), n_top_words = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained_20news_models = [model_GSMLDA_w2v_20news.get_beta(), model_GSMLDA_fasttext_20news.get_beta(), \n",
    "#                             model_GSMLDA_w2v_cbow_20news.get_beta(), model_GSMLDA_fasttext_cbow_20news.get_beta()]\n",
    "# pretrained_20news_coherences = [tools.topic_coherence(beta, 20, doc_term_matrix) for beta in pretrained_20news_models]\n",
    "\n",
    "# pretrained_20news_coherences_means = [coherences.mean() for coherences in pretrained_20news_coherences]\n",
    "# pretrained_20news_coherences_means_df = pd.DataFrame(pretrained_20news_coherences_means).to_latex()\n",
    "\n",
    "# print(pretrained_20news_coherences_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miao with Pretrained Vectors (outside text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText: from Wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss=1819.1591796875\n",
      "Epoch 5, loss=1000.1744995117188\n",
      "Epoch 10, loss=928.9122924804688\n",
      "Epoch 15, loss=708.18994140625\n",
      "Epoch 20, loss=647.6550903320312\n",
      "Epoch 25, loss=616.5306396484375\n",
      "Epoch 30, loss=599.0319213867188\n",
      "Epoch 35, loss=590.3344116210938\n",
      "Epoch 40, loss=579.5968627929688\n",
      "Epoch 45, loss=567.510498046875\n",
      "Epoch 50, loss=561.5753784179688\n",
      "Epoch 55, loss=556.7196655273438\n",
      "Epoch 60, loss=555.0986938476562\n",
      "Epoch 65, loss=555.7420043945312\n",
      "Epoch 70, loss=551.6532592773438\n",
      "Epoch 75, loss=551.369873046875\n"
     ]
    }
   ],
   "source": [
    "if isfile(\"model_GSMLDA_fasttext_wiki\"):\n",
    "    model_GSMLDA_fasttext_wiki = torch.load(\"model_GSMLDA_fasttext_wiki\")\n",
    "else:\n",
    "    model_GSMLDA_fasttext_wiki = TopicVAE.GSMLDA(args, embedding_matrix_fasttext_wiki)\n",
    "    optimizer_GSMLDA_fasttext_wiki = torch.optim.Adam(model_GSMLDA_fasttext_wiki.parameters(), args.learning_rate, \n",
    "                                            betas=(args.momentum, 0.999))\n",
    "    model_GSMLDA_fasttext_wiki = TopicVAE.train(model_GSMLDA_fasttext_wiki, args, optimizer_GSMLDA_fasttext_wiki, \n",
    "                                             doc_term_matrix_tensor)\n",
    "    torch.save(model_GSMLDA_fasttext_wiki, \"model_GSMLDA_fasttext_wiki\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSMLDA_fasttext_wiki_coherences = tools.topic_coherence(model_GSMLDA_fasttext_wiki.get_beta(), 20, doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSMLDA_fasttext_wiki_coherences_mean = GSMLDA_fasttext_wiki_coherences.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(GSMLDA_fasttext_wiki_coherences_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec: from ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miao without Pretrained Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss=727.3043212890625\n",
      "Epoch 5, loss=571.98828125\n",
      "Epoch 10, loss=567.2332153320312\n",
      "Epoch 15, loss=561.876708984375\n",
      "Epoch 20, loss=559.117431640625\n",
      "Epoch 25, loss=558.0926513671875\n",
      "Epoch 30, loss=555.7078247070312\n",
      "Epoch 35, loss=555.4019775390625\n",
      "Epoch 40, loss=554.8189697265625\n",
      "Epoch 45, loss=552.0185546875\n",
      "Epoch 50, loss=551.605712890625\n",
      "Epoch 55, loss=550.105712890625\n",
      "Epoch 60, loss=548.0165405273438\n",
      "Epoch 65, loss=547.9912719726562\n",
      "Epoch 70, loss=545.1119384765625\n",
      "Epoch 75, loss=546.1055297851562\n"
     ]
    }
   ],
   "source": [
    "if isfile(\"model_GSMLDA\"):\n",
    "    model_GSMLDA = torch.load(\"model_GSMLDA\")\n",
    "else:\n",
    "    model_GSMLDA = TopicVAE.GSMLDA(args)\n",
    "    optimizer_GSMLDA = torch.optim.Adam(model_GSMLDA.parameters(), args.learning_rate, betas=(args.momentum, 0.999))\n",
    "    model_GSMLDA = TopicVAE.train(model_GSMLDA, args, optimizer_GSMLDA, doc_term_matrix_tensor)\n",
    "    torch.save(model_GSMLDA, \"model_GSMLDA\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSMLDA_coherences = tools.topic_coherence(model_GSMLDA.get_beta(), 20, doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSMLDA_coherences_mean = GSMLDA_coherences.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1148.3212446470566\n"
     ]
    }
   ],
   "source": [
    "print(GSMLDA_coherences_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss=710.1594848632812\n",
      "Epoch 5, loss=571.350830078125\n",
      "Epoch 10, loss=564.021240234375\n",
      "Epoch 15, loss=560.5138549804688\n",
      "Epoch 20, loss=557.8563842773438\n",
      "Epoch 25, loss=556.1616821289062\n",
      "Epoch 30, loss=554.48095703125\n",
      "Epoch 35, loss=554.1760864257812\n",
      "Epoch 40, loss=552.4703369140625\n",
      "Epoch 45, loss=552.4207153320312\n",
      "Epoch 50, loss=550.7462768554688\n",
      "Epoch 55, loss=549.5635375976562\n",
      "Epoch 60, loss=548.7001953125\n",
      "Epoch 65, loss=548.9349365234375\n",
      "Epoch 70, loss=547.9478759765625\n",
      "Epoch 75, loss=547.1461181640625\n"
     ]
    }
   ],
   "source": [
    "if isfile(\"model_GSMLDA2\"):\n",
    "    model_GSMLDA2 = torch.load(\"model_GSMLDA2\")\n",
    "else:\n",
    "    model_GSMLDA2 = TopicVAE.GSMLDA(args)\n",
    "    optimizer_GSMLDA2 = torch.optim.Adam(model_GSMLDA2.parameters(), args.learning_rate, betas=(args.momentum, 0.999))\n",
    "    model_GSMLDA2 = TopicVAE.train(model_GSMLDA2, args, optimizer_GSMLDA2, doc_term_matrix_tensor)\n",
    "    torch.save(model_GSMLDA2, \"model_GSMLDA2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-586.8383929756021\n"
     ]
    }
   ],
   "source": [
    "GSMLDA2_coherences = tools.topic_coherence(model_GSMLDA2.get_beta(), 20, doc_term_matrix)\n",
    "GSMLDA2_coherences_mean = GSMLDA2_coherences.mean()\n",
    "print(GSMLDA2_coherences_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NVLDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristyn/Desktop/Python/math689project/TopicVAE.py:142: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  p = F.softmax(z)                                                # mixture probability\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss=614.6697998046875\n",
      "Epoch 5, loss=585.0731811523438\n",
      "Epoch 10, loss=567.2426147460938\n",
      "Epoch 15, loss=562.9029541015625\n",
      "Epoch 20, loss=558.6740112304688\n",
      "Epoch 25, loss=557.590087890625\n",
      "Epoch 30, loss=557.8560791015625\n",
      "Epoch 35, loss=556.2362670898438\n",
      "Epoch 40, loss=553.95068359375\n",
      "Epoch 45, loss=554.6138916015625\n",
      "Epoch 50, loss=554.067626953125\n",
      "Epoch 55, loss=553.5233764648438\n",
      "Epoch 60, loss=551.6415405273438\n",
      "Epoch 65, loss=552.6060791015625\n",
      "Epoch 70, loss=551.7682495117188\n",
      "Epoch 75, loss=549.5260009765625\n"
     ]
    }
   ],
   "source": [
    "if isfile(\"model_LDA\"):\n",
    "    model_LDA = torch.load(\"model_LDA\")\n",
    "else:\n",
    "    model_LDA = TopicVAE.LDA(args)\n",
    "    optimizer_LDA = torch.optim.Adam(model_LDA.parameters(), args.learning_rate, betas=(args.momentum, 0.999))\n",
    "    model_GSMLDA = TopicVAE.train(model_LDA, args, optimizer_LDA, doc_term_matrix_tensor)\n",
    "    torch.save(model_LDA, \"model_LDA\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Coherences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-603.2732064836742, -609.1866787140507, -638.079224907247, -618.5259246022016, -559.4402619940417, -1148.3212446470566, -1148.3212446470566]\n"
     ]
    }
   ],
   "source": [
    "# model_GSMLDA_w2v_20news_beta = model_GSMLDA_w2v_20news.get_beta()\n",
    "# tools.print_top_words(model_GSMLDA_w2v_20news_beta, vectorizer.get_feature_names(), n_top_words = 20)\n",
    "\n",
    "models = [model_GSMLDA_w2v_20news, model_GSMLDA_fasttext_20news, \n",
    "          model_GSMLDA_w2v_cbow_20news, model_GSMLDA_fasttext_cbow_20news, \n",
    "          model_GSMLDA_fasttext_wiki, model_GSMLDA, model_LDA]\n",
    "\n",
    "models_betas = [model.get_beta() for model in models]\n",
    "coherences = [tools.topic_coherence(beta, 20, doc_term_matrix) for beta in models_betas]\n",
    "coherences_means = [coherences.mean() for coherences in coherences]\n",
    "coherences_means_df = pd.DataFrame(coherences_means).to_latex()\n",
    "\n",
    "print(coherences_means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1105.52860479, -1164.20327375, -1197.69839877, -1123.01620449,\n",
       "       -1043.89114835, -1160.561923  , -1084.250682  , -1181.9325668 ,\n",
       "       -1186.24327668, -1138.67951998, -1103.92344374, -1048.49830253,\n",
       "       -1181.17941133, -1180.88287797, -1204.30671623, -1118.81880687,\n",
       "       -1030.34422392, -1045.8553841 , -1232.24115401, -1167.89015564,\n",
       "       -1173.79258331, -1172.38319386, -1128.58679358, -1235.17897937,\n",
       "       -1249.96496039, -1154.00782508, -1209.48595554, -1094.69523856,\n",
       "       -1254.911861  , -1070.44923484, -1219.2687084 , -1144.3954316 ,\n",
       "       -1163.73173323, -1177.94262558, -1136.26436815, -1003.17274192,\n",
       "       -1242.48854519, -1143.1228774 , -1092.03274886, -1096.468171  ,\n",
       "       -1152.84049136, -1140.69190316, -1075.64430344, -1245.91205374,\n",
       "       -1165.3811309 , -1237.28810388, -1184.1547856 , -1134.11874779,\n",
       "       -1139.04698852, -1078.69307215])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools.topic_coherence(model_LDA.get_beta(), 20, doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------Printing the Topics------------------\n",
      "\n",
      "     edu com posting host nntp writes university distribution article new reply mail just apr usa league john like michael don\n",
      "\n",
      "     file information space program available number section source email internet image software ftp pub code line using anonymous set new\n",
      "midea\n",
      "     people god think don said know say believe did right just question like life way israeli come says israel things\n",
      "\n",
      "     use key chip information encryption public data used bit new space keys technology number clipper message using available access need\n",
      "polit\n",
      "     people said know don think just right did going say time didn like says went told state president things came\n",
      "\n",
      "     edu com article posting university like just new world good problem does don distribution know computer writes reply science news\n",
      "\n",
      "     new government public number used time use national possible does years questions case order long april want information right non\n",
      "\n",
      "     don think like just time make way really know people good point things thing world right year want does didn\n",
      "\n",
      "     edu com writes article posting nntp host university distribution reply thanks usa mike john keywords columbia michael cmu sale cwru\n",
      "\n",
      "     people know don say believe did just think things time point man life says true really way question god different\n",
      "\n",
      "     edu com writes article university nntp host like posting new computer does usa reply know good world just org thanks\n",
      "comp \n",
      "     file edu available program image use ftp version window output graphics server files data software set pub info motif windows\n",
      "\n",
      "     edu com posting host nntp university writes article distribution reply thanks computer usa access gov net sale ohio keywords new\n",
      "\n",
      "     writes good think article don just play com team edu time really hockey year like game new better right news\n",
      "\n",
      "     writes like know just don com does edu new problem good world think time long need use right year article\n",
      "\n",
      "     edu com posting host university nntp writes article reply usa computer distribution gov know keywords netcom thanks michael ohio cmu\n",
      "\n",
      "     don article like just good think really know writes better make does com year little edu thing lot things time\n",
      "comp \n",
      "     com use space information software using nasa edu mail available files version windows file computer window mit data info does\n",
      "\n",
      "     edu com writes article posting host nntp university reply know distribution just computer andrew apr mark keywords news colorado access\n",
      "\n",
      "     just don know people way does time make state like use used world work sure need new high possible different\n",
      "polit\n",
      "     people gun armenian government said law states control crime right president time rights american firearms house united think don fact\n",
      "\n",
      "     edu com article posting nntp university writes host reply distribution thanks usa computer just know help sale keith cwru dept\n",
      "\n",
      "     think time know say people like just don good make right said point did let things question way going work\n",
      "\n",
      "     people think way know don time say years good point like going make does just question new right did reason\n",
      "comp \n",
      "     edu com thanks posting host computer mail using university windows distribution help software ibm nntp problem gov reply sun article\n",
      "\n",
      "     edu com writes nntp host university article distribution computer reply thanks usa know keywords michael new apple andrew institute like\n",
      "jesus|midea\n",
      "     people god jesus believe say life know think says just said does evidence bible israel did israeli christians death like\n",
      "\n",
      "     edu article writes com just know university good like think new host nntp does probably time world car don reply\n",
      "\n",
      "     team game year play games hockey good players edu season win teams nhl toronto don writes player goal division better\n",
      "\n",
      "     people think don know way like time point fact believe want right american years thing far new let government true\n",
      "\n",
      "     like just make good use don does people used going new time question com need work try number know way\n",
      "comp \n",
      "     windows edu dos com window card mac version software mail thanks video using files memory help mit internet mouse ram\n",
      "\n",
      "     edu com writes posting nntp article university host distribution reply thanks does usa like uiuc world news good sale cmu\n",
      "jesus\n",
      "     god jesus bible believe christian jews does christians faith christ turkish people truth true religion exist world church life atheists\n",
      "\n",
      "     edu com like don new article good year know want second just car time sure right years university better really\n",
      "comp \n",
      "     max drive scsi hard disk bit controller ide card drives bus problem drivers speed use floppy ibm data standard mode\n",
      "\n",
      "     edu article writes know don like new university does world thing want need problem think com posting good power science\n",
      "\n",
      "     people don right know think going way like make said really years just say did better got sure point good\n",
      "comp \n",
      "     max card air like reply bus hard use need work usa ide drives port edu mail end rochester windows phone\n",
      "\n",
      "     writes com edu article just like think really know good university don time got new car nntp best game posting\n",
      "\n",
      "     like just don use make think good problem long state year used time better center edu point want real news\n",
      "\n",
      "     don just like think good writes time really new know way did problem want people better sure article thing point\n",
      "\n",
      "     edu com writes host nntp article posting university distribution thanks computer usa mail news gov reply keith cwru andrew like\n",
      "\n",
      "     people think don say did just god time said didn things come way going says life know believe armenian like\n",
      "comp \n",
      "     use windows software using information version space program bit mail graphics data need files help computer problem set send dos\n",
      "\n",
      "     key chip encryption clipper keys government law security technology public use escrow des access secure algorithm enforcement communications nsa information\n",
      "\n",
      "     like just writes don know think year edu make good time does state need better com new article problem want\n",
      "polit\n",
      "     people don government think right make just gun know does way time fact like control going things president used said\n",
      "\n",
      "     edu com article writes posting host nntp university reply distribution usa thanks cmu keith cleveland pitt mike cwru apr john\n",
      "\n",
      "     space use information new data used key list number program file systems national nasa internet research mail service programs launch\n",
      "---------------End of Topics------------------\n"
     ]
    }
   ],
   "source": [
    "tools.print_top_words(model_GSMLDA2.get_beta(), vectorizer.get_feature_names(), n_top_words = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Perplexities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.perplexity(model_GSMLDA, doc_term_tensor_test)\n",
    "\n",
    "perplexities = [tools.perplexity(model, doc_term_tensor_test).item() for model in models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[871.3388671875, 877.4763793945312, 875.93212890625, 879.0941772460938, 929.1653442382812, 912.7308959960938, 914.7857055664062]\n"
     ]
    }
   ],
   "source": [
    "print(perplexities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Coherences OLD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.style.use(\"seaborn-deep\")\n",
    "\n",
    "x = GSMLDA_without_embedding_coherence\n",
    "y = GSMLDA2_20newsgroups_coherence\n",
    "\n",
    "plt.hist([x, y], label = [\"without embedding\", \"with 20newsgroups embedding\"])\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.show()\n",
    "\n",
    "# t test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_word_vecs = dict(zip(vectorizer.get_feature_names(), [model_GSMLDA2.word_embedding.weight[i] for i in range(model_GSMLDA2.word_embedding.weight.shape[0])]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GSMLDA2.word_embedding.weight.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([model_GSMLDA2.word_embedding.weight[i] for i in range(model_GSMLDA2.word_embedding.weight.shape[0])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_matrix = cosine_similarity(model_GSMLDA2.word_embedding.weight.detach().numpy(), \n",
    "                                   model_GSMLDA2.word_embedding.weight.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_closest_words(word, cos_sim_matrix, n):\n",
    "    word_index = vectorizer.get_feature_names().index(word)\n",
    "    close_words_indices = np.argsort(cos_sim_matrix[word_index])[-n:]\n",
    "    print(close_words_indices)\n",
    "    return [vectorizer.get_feature_names()[j] for j in close_words_indices]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_closest_words(\"nasa\", cos_sim_matrix, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_GSMLDA_cos_sim_matrix = cosine_similarity(model_GSMLDA_without_embedding.word_embedding.weight.detach().numpy(), \n",
    "                                   model_GSMLDA_without_embedding.word_embedding.weight.detach().numpy())\n",
    "n_closest_words(\"amendment\", model_GSMLDA_cos_sim_matrix, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_20newsgroups.most_similar(\"nasa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.perplexity(model_GSMLDA, doc_term_tensor_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_tensor_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_matrix_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_matrix_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:math689env]",
   "language": "python",
   "name": "conda-env-math689env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
