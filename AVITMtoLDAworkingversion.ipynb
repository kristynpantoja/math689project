{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AVITMtoLDAworkingversion.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kristynpantoja/math689project/blob/master/AVITMtoLDAworkingversion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "GABqU8qMLuin",
        "colab_type": "code",
        "outputId": "6228eabc-8bb7-47a1-e5c3-edd1ecf76940",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (0.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qwuFwsAW9IN_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "from torch.nn import Parameter\n",
        "import torch.nn.functional as F\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4_9vzhpQ9h_U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ProdLDA(nn.Module):\n",
        "\n",
        "    def __init__(self, net_arch):\n",
        "        super(ProdLDA, self).__init__()\n",
        "        ac = net_arch\n",
        "        self.net_arch = net_arch\n",
        "        # encoder\n",
        "        self.en1_fc     = nn.Linear(ac.num_input, ac.en1_units)             # 1995 -> 100\n",
        "        self.en2_fc     = nn.Linear(ac.en1_units, ac.en2_units)             # 100  -> 100\n",
        "        self.en2_drop   = nn.Dropout(0.2)\n",
        "        self.mean_fc    = nn.Linear(ac.en2_units, ac.num_topic)             # 100  -> 50\n",
        "        self.mean_bn    = nn.BatchNorm1d(ac.num_topic)                      # bn for mean\n",
        "        self.logvar_fc  = nn.Linear(ac.en2_units, ac.num_topic)             # 100  -> 50\n",
        "        self.logvar_bn  = nn.BatchNorm1d(ac.num_topic)                      # bn for logvar\n",
        "        # z\n",
        "        self.p_drop     = nn.Dropout(0.2)\n",
        "        # decoder\n",
        "        self.decoder = nn.Linear(ac.num_topic, ac.num_input)      # 50   -> 1995\n",
        "        self.decoder_bn = nn.BatchNorm1d(ac.num_topic)                      # bn for decoder\n",
        "        # prior mean and variance as constant buffers\n",
        "        prior_mean   = torch.Tensor(1, ac.num_topic).fill_(0)\n",
        "        prior_var    = torch.Tensor(1, ac.num_topic).fill_(ac.variance)\n",
        "        prior_logvar = prior_var.log()\n",
        "        self.register_buffer('prior_mean',    prior_mean)\n",
        "        self.register_buffer('prior_var',     prior_var)\n",
        "        self.register_buffer('prior_logvar',  prior_logvar)\n",
        "        # initialize decoder weight\n",
        "        if ac.init_mult != 0:\n",
        "            #std = 1. / math.sqrt( ac.init_mult * (ac.num_topic + ac.num_input))\n",
        "            self.decoder.weight.data.uniform_(0, ac.init_mult)\n",
        "        # remove BN's scale parameters\n",
        "#         self.logvar_bn .register_parameter('weight', None)\n",
        "#         self.mean_bn   .register_parameter('weight', None)\n",
        "#         self.decoder_bn.register_parameter('weight', None)\n",
        "#         self.decoder_bn.register_parameter('weight', None)\n",
        "        self.beta = nn.Parameter(torch.randn([self.net_arch.num_input, self.net_arch.num_topic]))\n",
        "\n",
        "    def forward(self, input, compute_loss=False, avg_loss=True):\n",
        "        # compute posterior\n",
        "        assert input.shape[1] == doc_term_matrix_tensor.shape[1], \"input isn't batch size x vocab size\"\n",
        "        en1 = F.softplus(self.en1_fc(input))                            # en1_fc   output\n",
        "        en2 = F.softplus(self.en2_fc(en1))                              # encoder2 output\n",
        "        en2 = self.en2_drop(en2)\n",
        "        posterior_mean   = self.mean_bn  (self.mean_fc  (en2))          # posterior mean\n",
        "        posterior_logvar = self.logvar_bn(self.logvar_fc(en2))          # posterior log variance\n",
        "        posterior_var    = posterior_logvar.exp()\n",
        "        # take sample\n",
        "        eps = Variable(input.data.new().resize_as_(posterior_mean.data).normal_()) # noise\n",
        "        z = posterior_mean + posterior_var.sqrt() * eps                 # reparameterization\n",
        "        assert z.shape[1] == self.net_arch.num_topic, \"hidden variable z (from TR) isn't batch size x num_topic\"\n",
        "        # get theta\n",
        "        p = F.softmax(z)                                                # mixture probability\n",
        "        p = self.p_drop(p)\n",
        "        assert p.shape[1] == self.net_arch.num_topic, \"p (theta) isn't same size as z\"\n",
        "        # return beta times theta, i.e. VxK times batch_size x K, need to transpose theta first\n",
        "        # do reconstruction\n",
        "#         print(self.beta.sum())\n",
        "        recon = F.softmax(self.decoder_bn(self.beta), dim=0).mm(p.t()).t()          # reconstructed distribution over vocabulary\n",
        "#         recon = p.mm(F.softmax(self.decoder_bn(self.beta), dim=0).t())\n",
        "        assert input.shape[1] == doc_term_matrix_tensor.shape[1], \"output isn't batch size x vocab size\"\n",
        "        \n",
        "        if compute_loss:\n",
        "            return recon, self.loss(input, recon, posterior_mean, posterior_logvar, posterior_var, avg_loss)\n",
        "        else:\n",
        "            return recon\n",
        "\n",
        "    def loss(self, input, recon, posterior_mean, posterior_logvar, posterior_var, avg=True):\n",
        "        # NL\n",
        "        NL  = -(input * (recon+1e-10).log()).sum(1) # vector with batch-size number of elements\n",
        "        # KLD, see Section 3.3 of Akash Srivastava and Charles Sutton, 2017, \n",
        "        # https://arxiv.org/pdf/1703.01488.pdf\n",
        "        prior_mean   = Variable(self.prior_mean).expand_as(posterior_mean) # batch-size x num_topics\n",
        "        prior_var    = Variable(self.prior_var).expand_as(posterior_mean)\n",
        "        prior_logvar = Variable(self.prior_logvar).expand_as(posterior_mean)\n",
        "        var_division    = posterior_var  / prior_var\n",
        "        diff            = posterior_mean - prior_mean\n",
        "        diff_term       = diff * diff / prior_var\n",
        "        logvar_division = prior_logvar - posterior_logvar\n",
        "        # put KLD together\n",
        "        KLD = 0.5 * ( (var_division + diff_term + logvar_division).sum(1) - self.net_arch.num_topic )\n",
        "#         print(KLD.mean())\n",
        "        # loss\n",
        "        loss = (NL + KLD)\n",
        "        # in traiming mode, return averaged loss. In testing mode, return individual loss\n",
        "        if avg:\n",
        "            return loss.mean() # averaged over all the documents in the batch (1/batch_size)*sum\n",
        "        else:\n",
        "            return loss\n",
        "          \n",
        "def train():\n",
        "    for epoch in range(args.num_epoch):\n",
        "        all_indices = torch.randperm(doc_term_matrix_tensor.size(0)).split(args.batch_size)\n",
        "        loss_epoch = 0.0\n",
        "        model.train()                   # switch to training mode\n",
        "        for batch_indices in all_indices:\n",
        "            if not args.nogpu: batch_indices = batch_indices.cuda()\n",
        "            input = Variable(doc_term_matrix_tensor[batch_indices])\n",
        "#             print(batch_indices.shape)\n",
        "#             print(input.shape)\n",
        "            recon, loss = model(input, compute_loss=True)\n",
        "            # optimize\n",
        "            optimizer.zero_grad()       # clear previous gradients\n",
        "            loss.backward()             # backprop\n",
        "            optimizer.step()            # update parameters\n",
        "            # report\n",
        "            loss_epoch += loss.data[0]    # add loss to loss_epoch, then take the average in the print statement\n",
        "        if epoch % 5 == 0:\n",
        "            print('Epoch {}, loss={}'.format(epoch, loss_epoch / len(all_indices)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l8VEfNT29xhT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jVr-x0Bk9o0E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# categories = ['talk.politics.guns', 'sci.space', 'soc.religion.christian',\n",
        "#               'misc.forsale', 'rec.sport.baseball', 'comp.sys.mac.hardware']\n",
        "categories = ['talk.politics.guns', 'sci.space']\n",
        "# newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
        "newsgroups_train = fetch_20newsgroups(subset='train')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YzHUuVzk1x1_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vectorizer = CountVectorizer(stop_words = 'english', min_df=.01, max_df=0.9, \n",
        "                             token_pattern = u'(?ui)\\\\b[a-z]{3,}\\\\b')\n",
        "count_vecs = vectorizer.fit_transform(newsgroups_train.data)\n",
        "doc_term_matrix = count_vecs.toarray()\n",
        "doc_term_matrix.shape # number of documents, number of words (in vocab)\n",
        "tokenizer = vectorizer.build_tokenizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bB1SYkcZBvLt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "doc_term_matrix_tensor = torch.from_numpy(doc_term_matrix).float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mq3D13vc-GpU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "from types import SimpleNamespace\n",
        "\n",
        "args_dict = {\"en1_units\" : 100, \"en2_units\" : 100, \"num_topic\" : 50, \n",
        "             \"batch_size\" : 200, \"optimizer\" : 80, \"learning_rate\" : 0.002, \n",
        "             \"momentum\" : 0.99, \"num_epoch\" : 80, \"init_mult\" : 1, \n",
        "             \"variance\" : 0.995, \"start\" : True, \"nogpu\" : True}\n",
        "args = SimpleNamespace(**args_dict)\n",
        "args.num_input = doc_term_matrix_tensor.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3LH7tOWIAGKd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = ProdLDA(args)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hHEE0EtRAnq6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(model.parameters(), args.learning_rate, betas=(args.momentum, 0.999))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7rfgjUfmAnua",
        "colab_type": "code",
        "outputId": "d4f2ff62-138c-42a4-e4db-400744797b8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "cell_type": "code",
      "source": [
        "train()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:106: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0, loss=621.9462890625\n",
            "Epoch 5, loss=584.5128173828125\n",
            "Epoch 10, loss=566.5389404296875\n",
            "Epoch 15, loss=560.741455078125\n",
            "Epoch 20, loss=559.405029296875\n",
            "Epoch 25, loss=559.4723510742188\n",
            "Epoch 30, loss=558.0155639648438\n",
            "Epoch 35, loss=555.9494018554688\n",
            "Epoch 40, loss=556.5142822265625\n",
            "Epoch 45, loss=555.7542724609375\n",
            "Epoch 50, loss=554.3941650390625\n",
            "Epoch 55, loss=553.204345703125\n",
            "Epoch 60, loss=552.0199584960938\n",
            "Epoch 65, loss=550.1524658203125\n",
            "Epoch 70, loss=551.4306640625\n",
            "Epoch 75, loss=549.3037719726562\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hdp1baXqAnx3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "associations = {\n",
        "    'jesus': ['prophet', 'jesus', 'matthew', 'christ', 'worship', 'church'],\n",
        "    'comp ': ['floppy', 'windows', 'microsoft', 'monitor', 'workstation', 'macintosh', \n",
        "              'printer', 'programmer', 'colormap', 'scsi', 'jpeg', 'compression'],\n",
        "    'car  ': ['wheel', 'tire'],\n",
        "    'polit': ['amendment', 'libert', 'regulation', 'president'],\n",
        "    'crime': ['violent', 'homicide', 'rape'],\n",
        "    'midea': ['lebanese', 'israel', 'lebanon', 'palest'],\n",
        "    'sport': ['coach', 'hitter', 'pitch'],\n",
        "    'gears': ['helmet', 'bike'],\n",
        "    'nasa ': ['orbit', 'spacecraft'],\n",
        "}\n",
        "def identify_topic_in_line(line):\n",
        "    topics = []\n",
        "    for topic, keywords in associations.items():\n",
        "        for word in keywords:\n",
        "            if word in line:\n",
        "                topics.append(topic)\n",
        "                break\n",
        "    return topics\n",
        "def print_top_words(beta, feature_names, n_top_words=10):\n",
        "    print('---------------Printing the Topics------------------')\n",
        "    for i in range(len(beta)):\n",
        "        line = \" \".join([feature_names[j] \n",
        "                            for j in beta[i].argsort()[:-n_top_words - 1:-1]])\n",
        "        topics = identify_topic_in_line(line)\n",
        "        print('|'.join(topics))\n",
        "        print('     {}'.format(line))\n",
        "    print('---------------End of Topics------------------')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TyiShF-JIyss",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1768
        },
        "outputId": "607bfdd3-4bab-4ed2-e49d-cf854f9bb978"
      },
      "cell_type": "code",
      "source": [
        "emb = model.decoder.weight.data.cpu().numpy().T\n",
        "print(\"shape of beta is \" + str(emb.shape))\n",
        "print_top_words(emb, vectorizer.get_feature_names())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of beta is (50, 1739)\n",
            "---------------Printing the Topics------------------\n",
            "car  \n",
            "     engineering entirely father happened remove supposed guys discussion previous needed\n",
            "\n",
            "     really type men peter claims version machine court greek time\n",
            "\n",
            "     carry fine sport brad years misc straight define groups federal\n",
            "\n",
            "     didn faster apart edward guess leave driving network link aren\n",
            "\n",
            "     copies style today questions add phone clock solution problem men\n",
            "\n",
            "     curious notes traffic adams playoffs risk does public straight sport\n",
            "\n",
            "     march sending thanks field standard keeping dealer just include excuse\n",
            "\n",
            "     ucs shown wondering kent bought messages example gone believed committed\n",
            "\n",
            "     clear ask available daniel citizens april alive different vga advance\n",
            "\n",
            "     sex rights sample electronic larry absolute security social source heard\n",
            "\n",
            "     heard controller love society tell mil auto sure held believe\n",
            "\n",
            "     huge attention print comes define eat surface keyboard star happen\n",
            "\n",
            "     wings review offers bet local yes term school bank steven\n",
            "\n",
            "     advantage changing user bring sold bob student columbia written carrying\n",
            "\n",
            "     rules watching europe direct recommend end william contrary tin technology\n",
            "\n",
            "     ideas team art sample sunday happens site black kevin soon\n",
            "\n",
            "     million property upgrade comments associated keyboard tradition ohio join allows\n",
            "\n",
            "     store legitimate section read exactly federal uxa human murder zero\n",
            "\n",
            "     actions newsgroups standard notes designed long rates uiuc ability computing\n",
            "\n",
            "     devices soviet difference love impossible making error attack cable ball\n",
            "\n",
            "     store industry corp notice existing program disclaimer status los circuit\n",
            "\n",
            "     sure break thinking committed academic went wasn discussed british report\n",
            "\n",
            "     aside flame fixed think usual ron ones escrow print warning\n",
            "\n",
            "     internet historical good ways paul answers excuse trial local usa\n",
            "\n",
            "     action problems uxa previous forward recognize group directly lord welcome\n",
            "\n",
            "     express consider gave intended york big file tin application fact\n",
            "\n",
            "     division clipper ibm islam koresh account automatic respect reason european\n",
            "\n",
            "     dale looked direct killing mil compare particular port continue just\n",
            "\n",
            "     flames told serve protect error section actually established public states\n",
            "\n",
            "     path bear cases advance examples right austin sin purpose atheist\n",
            "\n",
            "     jose mellon lee released benefit really happening leading hello hasn\n",
            "\n",
            "     paying millions views seen gotten popular administration david charles park\n",
            "\n",
            "     paul stephen fail motherboard force responses reported tek tried press\n",
            "polit\n",
            "     electronic value careful president older attacks urbana poor figure population\n",
            "\n",
            "     nature break complete congress despite summer like brad calling reasons\n",
            "\n",
            "     criminal low posting ecn technical standard engine goal hopefully result\n",
            "\n",
            "     choice lack condition include allows meet communications hockey difference definitely\n",
            "\n",
            "     wish missed dale black reduce purpose respond data crime winning\n",
            "\n",
            "     pick develop break accept lists popular hockey direction really somewhat\n",
            "\n",
            "     murder directly make net firearms original glad long gone faster\n",
            "\n",
            "     steve code grant bought years sunday copies specifically century woman\n",
            "\n",
            "     united answer function price scientific blue atheist francisco accepted lower\n",
            "\n",
            "     gets come double came allowed case things children sexual prevent\n",
            "midea\n",
            "     digital son israeli trouble modern products postings stopped expect died\n",
            "\n",
            "     netcom know nyx posted areas woman accept avoid live truth\n",
            "\n",
            "     digex james groups center weight father cleveland meant hit watching\n",
            "\n",
            "     opposed evidence arguments terms factor ohio billion nice definitely account\n",
            "\n",
            "     objective soldiers pub bush suggested acts gets peace network picture\n",
            "\n",
            "     announcement required fight times develop month early copy common according\n",
            "\n",
            "     texas love nation heaven time different color functions service act\n",
            "---------------End of Topics------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LLXFEytguoMl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1768
        },
        "outputId": "b3b3bc64-e596-4ab5-a694-f7aefed4ea24"
      },
      "cell_type": "code",
      "source": [
        "emb = model.beta.detach().numpy().T\n",
        "print(\"shape of beta is \" + str(emb.shape))\n",
        "print_top_words(emb, vectorizer.get_feature_names())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of beta is (50, 1739)\n",
            "---------------Printing the Topics------------------\n",
            "\n",
            "     edu com university like nntp host does year reply really\n",
            "jesus\n",
            "     max com jesus article son matthew new reply word men\n",
            "\n",
            "     just like don writes people good time article does think\n",
            "\n",
            "     com article university world use like need make distribution really\n",
            "\n",
            "     writes make use want time said right government new need\n",
            "\n",
            "     edu available use file program information ftp image pub data\n",
            "jesus\n",
            "     god jesus does believe people say think true christian question\n",
            "\n",
            "     writes com know does like just good time people new\n",
            "\n",
            "     don host like just use time need things good com\n",
            "\n",
            "     just com like article new think know does say good\n",
            "polit\n",
            "     people said know going armenian time government years president armenia\n",
            "\n",
            "     com writes article posting don nntp like know distribution new\n",
            "\n",
            "     edu article writes university posting nntp just host like distribution\n",
            "\n",
            "     edu com article writes posting nntp host university distribution reply\n",
            "\n",
            "     com people university just like think use does posting time\n",
            "\n",
            "     edu com article posting nntp host reply thanks usa computer\n",
            "\n",
            "     edu com writes don like know just nntp host think\n",
            "\n",
            "     edu com writes article posting host university just don like\n",
            "\n",
            "     just think edu don com know way does new host\n",
            "\n",
            "     new file gun public control government use know states internet\n",
            "comp \n",
            "     edu com article writes university don like know windows use\n",
            "\n",
            "     don edu just writes people like know article good time\n",
            "\n",
            "     edu max com article writes university nntp host posting distribution\n",
            "\n",
            "     don just think like know com good time way say\n",
            "\n",
            "     don like new make way time good world know science\n",
            "\n",
            "     writes just com like don good people know does time\n",
            "\n",
            "     people don think time say did just like god didn\n",
            "\n",
            "     people time right make just think good really did com\n",
            "\n",
            "     key file program use available server version software information files\n",
            "\n",
            "     edu host posting nntp university writes com distribution new thanks\n",
            "comp \n",
            "     think good does little windows university reply better way said\n",
            "\n",
            "     edu like don people think just good new does com\n",
            "\n",
            "     writes don like know host just think nntp new time\n",
            "\n",
            "     com writes article don university posting like nntp know edu\n",
            "\n",
            "     edu writes article posting nntp university host don good reply\n",
            "\n",
            "     just think writes does new way world need right time\n",
            "\n",
            "     com just like writes think good article time does used\n",
            "\n",
            "     edu com article posting nntp host writes university distribution reply\n",
            "\n",
            "     writes just like know don article think university time does\n",
            "\n",
            "     people don said think just god right say like time\n",
            "\n",
            "     like com don writes university just time know computer power\n",
            "\n",
            "     new information space use national file number key data program\n",
            "comp \n",
            "     use edu bit windows data com time information available using\n",
            "\n",
            "     edu article university writes think know time just does com\n",
            "\n",
            "     like writes just think make way right new want com\n",
            "\n",
            "     space use used key research bit university nasa control year\n",
            "jesus\n",
            "     god people know said say law believe jesus life did\n",
            "\n",
            "     use used don need new nntp know want jews using\n",
            "\n",
            "     edu com article writes posting host university nntp distribution just\n",
            "\n",
            "     article don know people think does good nntp problem time\n",
            "---------------End of Topics------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nTeSabr7K3qo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "beta = model.decoder.weight.detach()#.softmax(0)\n",
        "print(beta.sum(0))\n",
        "print(beta.shape)\n",
        "_, ind = torch.sort(beta, 0)\n",
        "print(ind.shape)\n",
        "# ind.numpy()[0:50, 0] - ind.numpy()[0:50, 1]\n",
        "print(np.array(sorted(vectorizer.get_feature_names(), key = lambda x: x[1]))[ind.numpy()][0:25, 0])\n",
        "print(np.array(sorted(vectorizer.get_feature_names(), key = lambda x: x[1]))[ind.numpy()][0:25, 1])\n",
        "print(np.array(sorted(vectorizer.get_feature_names(), key = lambda x: x[1]))[ind.numpy()][0:25, 2])\n",
        "print(np.array(sorted(vectorizer.get_feature_names(), key = lambda x: x[1]))[ind.numpy()][0:25, 3])\n",
        "print(np.array(sorted(vectorizer.get_feature_names(), key = lambda x: x[1]))[ind.numpy()][0:25, 4])\n",
        "print(np.array(sorted(vectorizer.get_feature_names(), key = lambda x: x[1]))[ind.numpy()][0:25, 5])\n",
        "print(np.array(sorted(vectorizer.get_feature_names(), key = lambda x: x[1]))[ind.numpy()][0:25, 6])\n",
        "print(np.array(sorted(vectorizer.get_feature_names(), key = lambda x: x[1]))[ind.numpy()][0:25, 7])\n",
        "print(np.array(sorted(vectorizer.get_feature_names(), key = lambda x: x[1]))[ind.numpy()][0:25, 8])\n",
        "print(np.array(sorted(vectorizer.get_feature_names(), key = lambda x: x[1]))[ind.numpy()][0:25, 9])\n",
        "\n",
        "# print(np.array(vectorizer.get_feature_names())[ind.numpy()][0:25, 4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gry54SsunU0B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(model.decoder.weight)\n",
        "model.decoder.weight.data.cpu()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nLdV3bB4N0eX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "\n",
        "def topic_coherence(beta, M, doc_term_matrix):\n",
        "  K = beta.shape[1] # beta has dim V x K\n",
        "  coherences = np.zeros(K)\n",
        "  for t in range(K):\n",
        "    index = np.argsort(-beta[:, t])[0:M]\n",
        "    cart_prod = product(list(index), list(index))\n",
        "    for ind1, ind2 in cart_prod:\n",
        "      if ind1 == ind2:\n",
        "        pass\n",
        "      else:\n",
        "        d_ind1 = (doc_term_matrix[:, ind1] > 0).sum()\n",
        "        d_ind12 = ((doc_term_matrix[:, ind1] > 0) & (doc_term_matrix[:, ind2] > 0)).sum()\n",
        "        coherences[t] += np.log1p(d_ind12) - np.log(d_ind1)\n",
        "\n",
        "  return coherences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5kRl6b_pOH_0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "f184be91-99fb-4fdb-aa0a-f8ae6e356165"
      },
      "cell_type": "code",
      "source": [
        "topic_coherence(model.beta.detach().numpy(), 20, doc_term_matrix)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-650.88923448, -817.20633464, -429.45869701, -522.86269983,\n",
              "       -556.02409611, -770.52725375, -578.23299271, -430.73181983,\n",
              "       -517.84426803, -515.44595657, -648.47097528, -478.74120291,\n",
              "       -500.46485713, -471.79991538, -500.91968408, -601.84733158,\n",
              "       -421.96658315, -419.21672536, -465.58039039, -761.66384369,\n",
              "       -510.87669811, -429.1398398 , -593.91115552, -502.82021129,\n",
              "       -565.29847244, -451.25286429, -588.95802632, -504.10260176,\n",
              "       -755.20671554, -533.82540282, -615.30444371, -437.38115235,\n",
              "       -518.48944887, -436.40228551, -531.05632365, -557.23560556,\n",
              "       -471.8931654 , -553.10739077, -484.81458719, -568.95545001,\n",
              "       -539.2576399 , -736.20418651, -636.66219113, -469.21569111,\n",
              "       -473.07713594, -773.87512275, -588.82486116, -639.52316987,\n",
              "       -503.64257899, -473.20491048])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "be2bpL_qOJWD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sorted(vectorizer.vocabulary_, key = lambda x: x[1])[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SbCZ3Wz-ONfd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "vocab = {\"hi\": 13, \"bye\": 2, \"hello\": 3}\n",
        "foo = zip(*sorted(vocab.items(), key = lambda x: x[1]))\n",
        "list(foo)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LhHX1qIm7WF_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def print_top_words(beta, feature_names, n_top_words=10):\n",
        "    print('---------------Printing the Topics------------------')\n",
        "    for i in range(len(beta)): # for all the rows (words in vocab) in beta,\n",
        "        line = \" \".join([feature_names[j] \n",
        "                            for j in beta[i].argsort()[:-n_top_words - 1:-1]])\n",
        "#         topics = identify_topic_in_line(line)\n",
        "#         print('|'.join(topics))\n",
        "        print('     {}'.format(line))\n",
        "    print('---------------End of Topics------------------')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7-yqzxLIBvbF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print_top_words(beta.numpy().T, sorted(vectorizer.vocabulary_, key = lambda x: x[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eevlzc-FCAAV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7OquNhh2CQfF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.bincount(np.array([4,6,3,6,8,2,6,78,89,5]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RoSnOvi2C0tx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"?\".join(\"bsc\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "awLPiUrVC-jq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "doc_term_matrix."
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}