{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "import TopicVAE\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import argparse\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec, FastText, KeyedVectors\n",
    "from os.path import isfile\n",
    "\n",
    "import tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data (20NewsGroups) and make the doc-term matrix, which is the input to all of our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words = 'english', min_df=.01, max_df=0.9, \n",
    "                             token_pattern = u'(?ui)\\\\b[a-z]{3,}\\\\b')\n",
    "count_vecs = vectorizer.fit_transform(newsgroups_train.data)\n",
    "doc_term_matrix = count_vecs.toarray()\n",
    "doc_term_matrix.shape # number of documents, number of words (in vocab)\n",
    "tokenizer = vectorizer.build_tokenizer()\n",
    "\n",
    "# note: vectorizer.get_feature_names() != vectorizer.vocabulary_\n",
    "\n",
    "doc_term_matrix_tensor = torch.from_numpy(doc_term_matrix).float()\n",
    "\n",
    "args_dict = {\"en1_units\" : 100, \"en2_units\" : 100, \"num_topic\" : 50, \n",
    "             \"batch_size\" : 200, \"optimizer\" : 80, \"learning_rate\" : 0.002, \n",
    "             \"momentum\" : 0.99, \"num_epoch\" : 80, \"init_mult\" : 1, \n",
    "             \"variance\" : 0.995, \"start\" : True, \"nogpu\" : True, \n",
    "             \"embedding_dim\" : 300, \"freeze\" : False}\n",
    "args = SimpleNamespace(**args_dict)\n",
    "args.num_input = doc_term_matrix_tensor.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Pretrained Vectors (20NewsGroups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make input to language models (word2vec, fasttext, etc.) ###\n",
    "\n",
    "# we would do some more preprocessing later\n",
    "newsgroups_train_preproc = []\n",
    "for document in newsgroups_train.data:\n",
    "    newsgroups_train_preproc.append(document.split())\n",
    "    \n",
    "dict_word_freq = dict(zip(vectorizer.get_feature_names(), list(doc_term_matrix.sum(0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec: Skip-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make language model using word2vec ###\n",
    "\n",
    "lm_w2v_20newsgroups = Word2Vec(sg=1, negative=5, size=300, window=10, min_count=1, max_vocab_size=None)\n",
    "# w2v.build_vocab(newsgroups_train_preproc)\n",
    "lm_w2v_20newsgroups.build_vocab_from_freq(word_freq = dict_word_freq)\n",
    "# train the model\n",
    "lm_w2v_20newsgroups.train(sentences=newsgroups_train_preproc,epochs=10, total_examples=doc_term_matrix.shape[1])\n",
    "# save the model\n",
    "lm_w2v_20newsgroups.save(\"lm_w2v_20newsgroups\")\n",
    "\n",
    "if not isfile(\"lm_w2v_20newsgroups\"):\n",
    "    lm_w2v_20newsgroups = Word2Vec(sg=1, negative=5, size=300, window=10, min_count=1, max_vocab_size=None)\n",
    "    # w2v.build_vocab(newsgroups_train_preproc)\n",
    "    lm_w2v_20newsgroups.build_vocab_from_freq(word_freq = dict_word_freq)\n",
    "    # train the model\n",
    "    lm_w2v_20newsgroups.train(sentences=newsgroups_train_preproc,epochs=10, total_examples=doc_term_matrix.shape[1])\n",
    "    # save the model\n",
    "    lm_w2v_20newsgroups.save(\"lm_w2v_20newsgroups\")\n",
    "else:\n",
    "    lm_w2v_20newsgroups = KeyedVectors.load(\"lm_w2v_20newsgroups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### get embedding matrix for word2vec language model trained on 20newsgroups ###\n",
    "\n",
    "embedding_matrix_w2v_20newsgroups = np.random.randn(doc_term_matrix.shape[1], 300)\n",
    "\n",
    "iterator = 0\n",
    "for word in vectorizer.get_feature_names():\n",
    "    if word in lm_20newsgroups.wv.vocab:\n",
    "        embedding_matrix_w2v_20newsgroups[iterator] = lm_20newsgroups.wv.word_vec(word)\n",
    "    else:\n",
    "        continue\n",
    "        # embedding_matrix2[iterator] = pretrained_language_model.wv.most_similar(word)\n",
    "        # or something like that\n",
    "    iterator += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Miao\" with Pretrained Vectors (on 20NewsGroups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't actually the method described in Miao et. al., since the encoder is different (it's not MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### \n",
    "\n",
    "model_GSMLDA2 = TopicVAE.GSMLDA(args, embedding_matrix_w2v_20newsgroups)\n",
    "optimizer_GSMLDA2 = torch.optim.Adam(model_GSMLDA2.parameters(), args.learning_rate, betas=(args.momentum, 0.999))\n",
    "model_GSMLDA2 = TopicVAE.train(model_GSMLDA2, args, optimizer_GSMLDA2, doc_term_matrix_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = model_GSMLDA2.beta.detach().numpy().T\n",
    "print(\"shape of beta is \" + str(emb.shape))\n",
    "tools.print_top_words(emb, vectorizer.get_feature_names(), n_top_words = 20)\n",
    "GSMLDA2_20newsgroups_coherence = tools.topic_coherence(emb.T, 20, doc_term_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miao with Pretrained Vectors (outside text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pre-Trained Word Vectors (FastText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained_language_model = api.load(\"fasttext-wiki-news-subwords-300\")\n",
    "# pretrained_language_model.save(\"fasttext-wiki-news-subwords-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = \"fasttext-wiki-news-subwords-300\"\n",
    "pretrained_language_model = KeyedVectors.load(EMBEDDING_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_language_model.most_similar(\"cat\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/math689env/lib/python3.7/site-packages/ipykernel/__main__.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.random.randn(doc_term_matrix.shape[1], 300)\n",
    "\n",
    "iterator = 0\n",
    "for word in vectorizer.get_feature_names():\n",
    "    if word in pretrained_language_model.vocab:\n",
    "        embedding_matrix[iterator] = pretrained_language_model.wv.word_vec(word)\n",
    "    else:\n",
    "        continue\n",
    "        # embedding_matrix[iterator] = pretrained_language_model.wv.most_similar(word)\n",
    "        # or something like that\n",
    "    iterator += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(embedding_matrix.sum(1) == 0) # when it was np.zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(pretrained_language_model.wv.word_vec(\"cats\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kristyn/Desktop/Python/math689project/TopicVAE.py:163: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  p = F.softmax(z)                                                # mixture probability\n",
      "/Users/kristyn/Desktop/Python/math689project/TopicVAE.py:111: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "  loss_epoch += loss.data[0]    # add loss to loss_epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss=1817.055419921875\n",
      "Epoch 5, loss=1798.135986328125\n",
      "Epoch 10, loss=1801.40576171875\n",
      "Epoch 15, loss=1801.5257568359375\n",
      "Epoch 20, loss=1795.7042236328125\n",
      "Epoch 25, loss=1797.6937255859375\n",
      "Epoch 30, loss=1795.608642578125\n",
      "Epoch 35, loss=1803.2735595703125\n",
      "Epoch 40, loss=1797.1104736328125\n",
      "Epoch 45, loss=1797.1998291015625\n",
      "Epoch 50, loss=1800.6058349609375\n",
      "Epoch 55, loss=1800.102783203125\n",
      "Epoch 60, loss=1796.39306640625\n",
      "Epoch 65, loss=1798.9296875\n",
      "Epoch 70, loss=1795.7803955078125\n",
      "Epoch 75, loss=1794.635986328125\n"
     ]
    }
   ],
   "source": [
    "model_GSMLDA = TopicVAE.GSMLDA(args, embedding_matrix)\n",
    "optimizer_GSMLDA = torch.optim.Adam(model_GSMLDA.parameters(), args.learning_rate, betas=(args.momentum, 0.999))\n",
    "model_GSMLDA = TopicVAE.train(model_GSMLDA, args, optimizer_GSMLDA, doc_term_matrix_tensor)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = model_GSMLDA.beta.detach().numpy().T\n",
    "print(\"shape of beta is \" + str(emb.shape))\n",
    "tools.print_top_words(emb, vectorizer.get_feature_names(), n_top_words = 20)\n",
    "tools.topic_coherence(emb.T, 20, doc_term_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Miao without Pretrained Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss=689.626220703125\n",
      "Epoch 5, loss=569.250244140625\n",
      "Epoch 10, loss=563.5982666015625\n",
      "Epoch 15, loss=560.0499877929688\n",
      "Epoch 20, loss=559.30419921875\n",
      "Epoch 25, loss=555.1755981445312\n",
      "Epoch 30, loss=553.8216552734375\n",
      "Epoch 35, loss=552.78125\n",
      "Epoch 40, loss=551.3523559570312\n",
      "Epoch 45, loss=549.9356689453125\n",
      "Epoch 50, loss=548.69189453125\n",
      "Epoch 55, loss=548.068115234375\n",
      "Epoch 60, loss=548.7611083984375\n",
      "Epoch 65, loss=546.657470703125\n",
      "Epoch 70, loss=545.8392333984375\n",
      "Epoch 75, loss=545.7095336914062\n"
     ]
    }
   ],
   "source": [
    "model_GSMLDA_without_embedding = TopicVAE.GSMLDA(args)\n",
    "optimizer_GSMLDA_without_embedding = torch.optim.Adam(model_GSMLDA_without_embedding.parameters(), args.learning_rate, betas=(args.momentum, 0.999))\n",
    "model_GSMLDA_without_embedding = TopicVAE.train(model_GSMLDA_without_embedding, args, optimizer_GSMLDA_without_embedding, doc_term_matrix_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of beta is (50, 1739)\n",
      "---------------Printing the Topics------------------\n",
      "gears\n",
      "     edu com writes article posting nntp university host reply distribution usa cwru john state bike know mike robert cso rochester\n",
      "\n",
      "     edu com writes article nntp posting host university distribution reply just know uiuc like usa think michael state car don\n",
      "\n",
      "     edu com writes nntp host article university posting reply distribution usa like know news computer thanks apr michael john ohio\n",
      "\n",
      "     people time state world right don years make just know public does american number fact point control new work gun\n",
      "\n",
      "     edu com posting writes nntp article host university distribution thanks usa computer mail like access keywords know gov ohio news\n",
      "jesus\n",
      "     god does believe christian truth christians jesus evidence bible religion people true faith argument law exist church question atheists religious\n",
      "\n",
      "     edu com writes article university nntp posting host distribution usa news like mike good thanks car washington year john steve\n",
      "\n",
      "     key space information use clipper data available chip program keys security escrow encryption file number nasa public new technology used\n",
      "\n",
      "     just think people time like know want does believe say make things really read come wrong world case long years\n",
      "\n",
      "     don like just people know think time good really point did come said things need make say believe let going\n",
      "comp \n",
      "     graphics edu windows version available software com data mit window ftp server use files based display dos mac set motif\n",
      "\n",
      "     people think said right don say gun like way time point years things fact just good question know non going\n",
      "comp \n",
      "     edu com university posting host distribution use mail computer writes windows like know systems does using gov phone help need\n",
      "\n",
      "     don just know like writes article make better way world going really edu work want sure bad lot good thing\n",
      "\n",
      "     god people know said say don think just didn did believe like says life time good man come things way\n",
      "midea\n",
      "     israel people turkish israeli jews armenian government armenia state turks rights world war population right peace arab human land soviet\n",
      "\n",
      "     com edu like know writes distribution posting just want computer don time does gov article work need problem nasa university\n",
      "comp \n",
      "     use windows space available using data window bit program computer software set used mail server new systems edu need files\n",
      "\n",
      "     edu writes article posting nntp university host com distribution like know reply usa thanks just don computer keywords mike looking\n",
      "\n",
      "     edu com nntp writes posting host article university reply distribution thanks like usa gov mail just net help world know\n",
      "jesus\n",
      "     god people know don jesus said say think did time believe like life going does come way just says day\n",
      "\n",
      "     file program use information files output space key info code internet address build send data line number title directory write\n",
      "\n",
      "     edu writes com article university posting host good like just know nntp world distribution reply car mark really news netcom\n",
      "polit\n",
      "     government new law president states public national encryption april health use gun congress american control united administration information technology federal\n",
      "\n",
      "     use new used public government number people encryption does long technology information program time order center questions house non private\n",
      "\n",
      "     don just think writes time good like know really years year say com new did power does got way second\n",
      "\n",
      "     com edu writes article don like does just university know use world help new problem want good need posting time\n",
      "jesus\n",
      "     god people jesus say don know said think believe life didn just says bible christian like did christians way time\n",
      "\n",
      "     don just like know think way really good edu time com right writes make want does going sure science question\n",
      "\n",
      "     edu com article like university does writes know don need host problem want help just reply use new used news\n",
      "\n",
      "     don think like good just time article know really better car way com make going years let point best say\n",
      "\n",
      "     com like writes just article don edu good time does new better world make want really nntp david doesn state\n",
      "\n",
      "     edu writes article com posting university nntp just know don good reply like host car got think news really does\n",
      "\n",
      "     time use don like work make new does just used long want need science case way read public group doing\n",
      "\n",
      "     com writes edu like article just distribution use problem computer new does host university world good don want help used\n",
      "\n",
      "     max edu com reply air host usa thanks andrew umd computer university net phone tin posting keywords address access newsreader\n",
      "\n",
      "     available file information program ftp image use files space edu pub email software server data send list faq info key\n",
      "polit\n",
      "     people think don government said right did say time way going gun make year just does point president things years\n",
      "comp \n",
      "     edu com scsi posting computer host ibm internet card video mac thanks nntp university distribution apple mail using work memory\n",
      "\n",
      "     like don just edu writes good does university think know way article did new david posting world got nntp probably\n",
      "comp \n",
      "     use space information file mail key windows program available using window version email data code edu mit systems nasa list\n",
      "comp \n",
      "     edu com posting like know new need university host distribution does thanks good windows article writes problem reply computer don\n",
      "\n",
      "     good don writes com just think article new game know got time play right games did posting really bad car\n",
      "\n",
      "     people think going just time know don said good like make say years things new did want does way far\n",
      "\n",
      "     people think say did point make just jews does right world fact government going today human law book mean given\n",
      "\n",
      "     team game games year season play hockey nhl league players win new teams player toronto division points won second san\n",
      "comp \n",
      "     drive scsi card bit hard dos mac disk bus drives problem controller speed ide ibm use memory video mode ram\n",
      "\n",
      "     edu max com university nntp host article writes reply usa pitt cmu andrew mail banks robert freenet john steve state\n",
      "\n",
      "     edu com nntp article posting writes university host distribution reply usa know thanks cleveland uiuc sale like computer cwru tin\n",
      "\n",
      "     don just com edu time does way think know article like want world really little question writes good doesn make\n",
      "---------------End of Topics------------------\n"
     ]
    }
   ],
   "source": [
    "emb = model_GSMLDA_without_embedding.beta.detach().numpy().T\n",
    "print(\"shape of beta is \" + str(emb.shape))\n",
    "tools.print_top_words(emb, vectorizer.get_feature_names(), n_top_words = 20)\n",
    "GSMLDA_without_embedding_coherence = tools.topic_coherence(emb.T, 20, doc_term_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Training Word Vectors Using 20Newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ideally, we would do some preprocessing\n",
    "newsgroups_train_preproc = []\n",
    "for document in newsgroups_train.data:\n",
    "    newsgroups_train_preproc.append(document.split())\n",
    "\n",
    "dict_word_freq = dict(zip(vectorizer.get_feature_names(), list(doc_term_matrix.sum(0))))\n",
    "\n",
    "# make the model\n",
    "lm_20newsgroups = Word2Vec(sg=1, negative=5, size=300, window=10, min_count=1, max_vocab_size=None)\n",
    "# w2v.build_vocab(newsgroups_train_preproc)\n",
    "lm_20newsgroups.build_vocab_from_freq(word_freq = dict_word_freq)\n",
    "# train the model\n",
    "lm_20newsgroups.train(sentences=newsgroups_train_preproc,epochs=10, total_examples=doc_term_matrix.shape[1])\n",
    "# save the model\n",
    "lm_20newsgroups.save(\"lm_20newsgroups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix2 = np.random.randn(doc_term_matrix.shape[1], 300)\n",
    "\n",
    "iterator = 0\n",
    "for word in vectorizer.get_feature_names():\n",
    "    if word in lm_20newsgroups.wv.vocab:\n",
    "        embedding_matrix2[iterator] = lm_20newsgroups.wv.word_vec(word)\n",
    "    else:\n",
    "        continue\n",
    "        # embedding_matrix2[iterator] = pretrained_language_model.wv.most_similar(word)\n",
    "        # or something like that\n",
    "    iterator += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss=683.7957153320312\n",
      "Epoch 5, loss=567.4393310546875\n",
      "Epoch 10, loss=559.78271484375\n",
      "Epoch 15, loss=554.87255859375\n",
      "Epoch 20, loss=552.8372192382812\n",
      "Epoch 25, loss=550.0009155273438\n",
      "Epoch 30, loss=547.9387817382812\n",
      "Epoch 35, loss=546.999267578125\n",
      "Epoch 40, loss=545.3956909179688\n",
      "Epoch 45, loss=543.1943969726562\n",
      "Epoch 50, loss=544.11181640625\n",
      "Epoch 55, loss=541.7147827148438\n",
      "Epoch 60, loss=540.9940795898438\n",
      "Epoch 65, loss=542.0515747070312\n",
      "Epoch 70, loss=540.8637084960938\n",
      "Epoch 75, loss=541.0808715820312\n"
     ]
    }
   ],
   "source": [
    "model_GSMLDA2 = TopicVAE.GSMLDA(args, embedding_matrix2)\n",
    "optimizer_GSMLDA2 = torch.optim.Adam(model_GSMLDA2.parameters(), args.learning_rate, betas=(args.momentum, 0.999))\n",
    "model_GSMLDA2 = TopicVAE.train(model_GSMLDA2, args, optimizer_GSMLDA2, doc_term_matrix_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of beta is (50, 1739)\n",
      "---------------Printing the Topics------------------\n",
      "\n",
      "     edu com posting nntp university host thanks mail distribution computer sale new usa reply software looking fax keywords need version\n",
      "\n",
      "     team game year hockey games toronto win play period new edu nhl season san pittsburgh league division chicago power players\n",
      "\n",
      "     gun new control national american states april state united law police government public information military use crime congress guns house\n",
      "comp \n",
      "     card windows problem drive use software mouse apple using mac ibm video dos bit memory driver monitor screen modem computer\n",
      "polit\n",
      "     think people going don know president time did make say like said just work believe money gun clinton mean day\n",
      "\n",
      "     team year game games good better season play think win players hockey time don player did toronto years league runs\n",
      "\n",
      "     edu writes article nntp university host posting com reply state andrew distribution computer usa cmu case science ohio cwru cleveland\n",
      "\n",
      "     writes don article just like think know good edu com really does time way make say right want did doesn\n",
      "\n",
      "     gun guns people control weapons state crime law health clinton police american government rate public firearms national tax year states\n",
      "gears\n",
      "     com car writes article like just good don know bike edu dod cars engine really miles got buy little lot\n",
      "\n",
      "     edu com writes article nntp posting university host just distribution reply know org world usa like virginia jim news uiuc\n",
      "\n",
      "     available file image use edu version program window software mit information files color info ftp server com motif source based\n",
      "gears\n",
      "     com car don like just good bike article writes cars really engine better think know dod lot time little thing\n",
      "comp \n",
      "     windows thanks mail sale help software version fax graphics card window using need host university com dos unix use email\n",
      "\n",
      "     don know time just like didn good car got said think going did people really say went left way water\n",
      "\n",
      "     edu writes article nntp com posting host university distribution reply state world usa uiuc news apr computer david science john\n",
      "jesus\n",
      "     god christian jesus does believe people say bible faith christians think religion true christianity church science exist law truth atheists\n",
      "\n",
      "     writes article don just com think like people know way make say things time did right read does really good\n",
      "\n",
      "     don like know just think good com article time way does people want make writes problem need question right things\n",
      "\n",
      "     max key chip clipper encryption government technology keys access law new security space used algorithm communications nsa escrow private need\n",
      "\n",
      "     key use chip public clipper encryption security keys government data des used bit technology number secure bits law access pgp\n",
      "comp \n",
      "     drive scsi bit disk use mac hard dos data memory mode controller speed bus does drives ram windows ide card\n",
      "\n",
      "     people don said know think did just going like didn say way right time day come let want says told\n",
      "\n",
      "     com edu posting nntp host writes article university distribution reply know thanks usa computer new like access does mail phone\n",
      "jesus\n",
      "     god jesus people hell know christ son did time man life said believe say world come day father says good\n",
      "\n",
      "     edu university host nntp posting article writes state com reply andrew usa pitt john cleveland distribution ohio computer cmu michael\n",
      "comp \n",
      "     drive scsi card mac hard bit problem apple use speed windows dos ide disk software chip ibm drives memory does\n",
      "jesus\n",
      "     god people does say christian believe think law truth evidence jesus bible christians religious true don religion question church atheists\n",
      "midea\n",
      "     people israel israeli turkish jews armenian government rights world turks right greek state jewish war peace arab killed today land\n",
      "\n",
      "     people said know time didn like did just say don told went came going says started armenian come left right\n",
      "\n",
      "     people don think like just make say does writes article know right did fact way case believe time isn point\n",
      "\n",
      "     use time com like does space good new used don need want make using know work just systems current nasa\n",
      "\n",
      "     edu com nntp posting host university writes article distribution reply usa computer thanks mail world new internet gov keywords sale\n",
      "\n",
      "     edu university article nntp host posting state pitt ohio cwru reply cleveland gordon banks freenet writes science andrew computer uiuc\n",
      "\n",
      "     com don just like think writes good know article really make does way time problem want right sure better thing\n",
      "comp \n",
      "     file program use window files output number version set available display code application size using source line information image windows\n",
      "\n",
      "     com use edu new does mail software using help version information used systems need distribution work university available like list\n",
      "nasa \n",
      "     space nasa research center earth data gov information anonymous orbit moon program new internet service launch news science flight national\n",
      "\n",
      "     com edu writes article just like don know good university posting does think nntp really host new distribution want netcom\n",
      "\n",
      "     edu com posting university writes nntp host article distribution reply mail thanks computer usa world new net know does keywords\n",
      "\n",
      "     edu file mail available internet ftp pub data information software email send use files image anonymous server list faq privacy\n",
      "\n",
      "     edu com article writes posting host nntp university reply distribution apr world science org gov john uucp uiuc news know\n",
      "midea\n",
      "     people israel government israeli jews turkish war peace world right human rights fact jewish armenian history arab political men state\n",
      "\n",
      "     com like writes don article just good know think edu make way time want does really thing new better pretty\n",
      "\n",
      "     com edu writes article like just don know does good think way need posting make want host question new time\n",
      "\n",
      "     com edu writes article posting know nntp university like host just don does distribution good world think reply new usa\n",
      "\n",
      "     think don just like people good know make things want time problem really does writes article right point going say\n",
      "gears\n",
      "     com good don like just car article time know writes make want think does used little really bike new way\n",
      "polit\n",
      "     government people use years president new administration public general time support make money american law states clinton right work private\n",
      "\n",
      "     max edu university usa air win distribution game van games toronto host team nntp baseball mike reply posting chicago lost\n",
      "---------------End of Topics------------------\n"
     ]
    }
   ],
   "source": [
    "emb = model_GSMLDA2.beta.detach().numpy().T\n",
    "print(\"shape of beta is \" + str(emb.shape))\n",
    "tools.print_top_words(emb, vectorizer.get_feature_names(), n_top_words = 20)\n",
    "GSMLDA2_20newsgroups_coherence = tools.topic_coherence(emb.T, 20, doc_term_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Coherences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plt.style.use(\"seaborn-deep\")\n",
    "\n",
    "x = GSMLDA_without_embedding_coherence\n",
    "y = GSMLDA2_20newsgroups_coherence\n",
    "\n",
    "plt.hist([x, y], label = [\"without embedding\", \"with 20newsgroups embedding\"])\n",
    "plt.legend(loc = 'upper right')\n",
    "plt.show()\n",
    "\n",
    "# t test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_word_vecs = dict(zip(vectorizer.get_feature_names(), [model_GSMLDA2.word_embedding.weight[i] for i in range(model_GSMLDA2.word_embedding.weight.shape[0])]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_GSMLDA2.word_embedding.weight.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1739"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1739"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([model_GSMLDA2.word_embedding.weight[i] for i in range(model_GSMLDA2.word_embedding.weight.shape[0])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim_matrix = cosine_similarity(model_GSMLDA2.word_embedding.weight.detach().numpy(), \n",
    "                                   model_GSMLDA2.word_embedding.weight.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_closest_words(word, cos_sim_matrix, n):\n",
    "    word_index = vectorizer.get_feature_names().index(word)\n",
    "    close_words_indices = np.argsort(cos_sim_matrix[word_index])[-n:]\n",
    "    print(close_words_indices)\n",
    "    return [vectorizer.get_feature_names()[j] for j in close_words_indices]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 501  827  426  471 1370  980 1492  164 1547  813  348  418  608   49\n",
      " 1457  787  849  151  672 1026]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['electronic',\n",
       " 'ken',\n",
       " 'development',\n",
       " 'douglas',\n",
       " 'sciences',\n",
       " 'mil',\n",
       " 'steve',\n",
       " 'bitnet',\n",
       " 'technology',\n",
       " 'jim',\n",
       " 'corp',\n",
       " 'design',\n",
       " 'flight',\n",
       " 'alt',\n",
       " 'space',\n",
       " 'institute',\n",
       " 'laboratory',\n",
       " 'bell',\n",
       " 'gov',\n",
       " 'nasa']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_closest_words(\"nasa\", cos_sim_matrix, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 406   17  403 1449  594 1397  321 1223  307  983  530  812 1677  565\n",
      "  355 1545  345  447 1619   51]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['define',\n",
       " 'activities',\n",
       " 'decision',\n",
       " 'soul',\n",
       " 'fighting',\n",
       " 'serve',\n",
       " 'concept',\n",
       " 'protect',\n",
       " 'community',\n",
       " 'million',\n",
       " 'europe',\n",
       " 'jews',\n",
       " 'war',\n",
       " 'facts',\n",
       " 'count',\n",
       " 'tech',\n",
       " 'cool',\n",
       " 'discuss',\n",
       " 'unable',\n",
       " 'amendment']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_GSMLDA_cos_sim_matrix = cosine_similarity(model_GSMLDA_without_embedding.word_embedding.weight.detach().numpy(), \n",
    "                                   model_GSMLDA_without_embedding.word_embedding.weight.detach().numpy())\n",
    "n_closest_words(\"amendment\", model_GSMLDA_cos_sim_matrix, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/math689env/lib/python3.7/site-packages/ipykernel/__main__.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('univ', 0.950654149055481),\n",
       " ('stanford', 0.9414347410202026),\n",
       " ('lee', 0.9314770102500916),\n",
       " ('phil', 0.930532693862915),\n",
       " ('mil', 0.9267240166664124),\n",
       " ('edward', 0.925822913646698),\n",
       " ('batf', 0.9226192235946655),\n",
       " ('ryan', 0.9212854504585266),\n",
       " ('tin', 0.9206329584121704),\n",
       " ('washington', 0.920329213142395)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_20newsgroups.most_similar(\"nasa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
