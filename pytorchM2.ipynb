{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorchM2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kristynpantoja/math689project/blob/master/pytorchM2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Yzom68CRUCUt",
        "colab_type": "code",
        "outputId": "5a7a5f3f-292d-4fc5-d6fb-8469e14b7db6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (0.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L382anKLUwuE",
        "colab_type": "code",
        "outputId": "102f5740-193c-4c61-fd5d-6375540e4e73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install torchvision"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.2.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision) (0.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (5.3.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pJ2ybE0_FuhI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Model Parameters"
      ]
    },
    {
      "metadata": {
        "id": "lsJa9n2aXLrD",
        "colab_type": "code",
        "outputId": "12670c06-a05e-454d-ea62-87cb7eda3fa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# from types import SimpleNamespace\n",
        "\n",
        "# args_dict = {\"batch_size\" : 50, \"epochs\" : 50, \"no_cuda\" : False, \"seed\" : 1, \"log_interval\" : 10}\n",
        "# args = SimpleNamespace(**args_dict)\n",
        "# args.epochs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 252
        }
      ]
    },
    {
      "metadata": {
        "id": "Y96bktYniWeB",
        "colab_type": "code",
        "outputId": "647493d5-9835-4d9b-e6b4-04b1d8cbd04d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/a4/d10c0acc8528d838cda5eede0ee9c784caa598dbf40bd0911ff8d067a7eb/gensim-3.6.0-cp36-cp36m-manylinux1_x86_64.whl (23.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 23.6MB 1.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
            "Collecting smart-open>=1.2.1 (from gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/1f/6f27e3682124de63ac97a0a5876da6186de6c19410feab66c1543afab055/smart_open-1.7.1.tar.gz\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.6)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (0.19.1)\n",
            "Collecting boto>=2.32 (from smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/10/c0b78c27298029e4454a472a1919bde20cb182dab1662cec7f2ca1dcc523/boto-2.49.0-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.4MB 13.2MB/s \n",
            "\u001b[?25hCollecting bz2file (from smart-open>=1.2.1->gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/61/39/122222b5e85cd41c391b68a99ee296584b2a2d1d233e7ee32b4532384f2d/bz2file-0.98.tar.gz\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
            "Collecting boto3 (from smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/b9/7acc466df1f41a8c1f0a74e371ec7ee627162d325b80d7201dfd7b9521b1/boto3-1.9.35-py2.py3-none-any.whl (128kB)\n",
            "\u001b[K    100% |████████████████████████████████| 133kB 24.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.10.15)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
            "Collecting jmespath<1.0.0,>=0.7.1 (from boto3->smart-open>=1.2.1->gensim)\n",
            "  Downloading https://files.pythonhosted.org/packages/b7/31/05c8d001f7f87f0f07289a5fc0fc3832e9a57f2dbd4d3b0fee70e0d51365/jmespath-0.9.3-py2.py3-none-any.whl\n",
            "Collecting s3transfer<0.2.0,>=0.1.10 (from boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/14/2a0004d487464d120c9fb85313a75cd3d71a7506955be458eebfe19a6b1d/s3transfer-0.1.13-py2.py3-none-any.whl (59kB)\n",
            "\u001b[K    100% |████████████████████████████████| 61kB 21.0MB/s \n",
            "\u001b[?25hCollecting botocore<1.13.0,>=1.12.35 (from boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/76/5674019dcdc6475363a1b6fe93ec6dfdce05ec2e94339b177a1ac782d8f6/botocore-1.12.35-py2.py3-none-any.whl (4.7MB)\n",
            "\u001b[K    100% |████████████████████████████████| 4.7MB 5.8MB/s \n",
            "\u001b[?25hCollecting docutils>=0.10 (from botocore<1.13.0,>=1.12.35->boto3->smart-open>=1.2.1->gensim)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/fa/08e9e6e0e3cbd1d362c3bbee8d01d0aedb2155c4ac112b19ef3cae8eed8d/docutils-0.14-py3-none-any.whl (543kB)\n",
            "\u001b[K    100% |████████████████████████████████| 552kB 20.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.35->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
            "Building wheels for collected packages: smart-open, bz2file\n",
            "  Running setup.py bdist_wheel for smart-open ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/23/00/44/e5b939f7a80c04e32297dbd6d96fa3065af89ecf57e2b5f89f\n",
            "  Running setup.py bdist_wheel for bz2file ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/81/75/d6/e1317bf09bf1af5a30befc2a007869fa6e1f516b8f7c591cb9\n",
            "Successfully built smart-open bz2file\n",
            "Installing collected packages: boto, bz2file, jmespath, docutils, botocore, s3transfer, boto3, smart-open, gensim\n",
            "Successfully installed boto-2.49.0 boto3-1.9.35 botocore-1.12.35 bz2file-0.98 docutils-0.14 gensim-3.6.0 jmespath-0.9.3 s3transfer-0.1.13 smart-open-1.7.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-D3sQR-gF0Vk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Data: 20newsgroups\n",
        "We get the document-term matrix"
      ]
    },
    {
      "metadata": {
        "id": "f5gixJ2PhDZy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from types import SimpleNamespace\n",
        "\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "import numpy as np\n",
        "import torch\n",
        "# from gensim.models import Word2Vec\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# categories = ['talk.politics.guns', 'sci.space', 'soc.religion.christian',\n",
        "#               'misc.forsale', 'rec.sport.baseball', 'comp.sys.mac.hardware']\n",
        "categories = ['talk.politics.guns', 'sci.space']\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
        "vectorizer = CountVectorizer(stop_words = 'english', min_df=.01, max_df=0.9, \n",
        "                             token_pattern = u'(?ui)\\\\b[a-z]{3,}\\\\b')\n",
        "count_vecs = vectorizer.fit_transform(newsgroups_train.data)\n",
        "doc_term_matrix = count_vecs.toarray()\n",
        "doc_term_matrix.shape # number of documents, number of words (in vocab)\n",
        "tokenizer = vectorizer.build_tokenizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XtIb9CFS59LP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b40c8dc2-7203-4111-cb37-c7735bc2ecbf"
      },
      "cell_type": "code",
      "source": [
        "doc_term_matrix.shape[1] # vocab size"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2441"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "metadata": {
        "id": "ilQe6iCsZ9VO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b76278d8-b289-41ad-a5ae-d33f45dc3ad8"
      },
      "cell_type": "code",
      "source": [
        "len(vectorizer.get_feature_names())"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2441"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "metadata": {
        "id": "oft5ScQFZyEw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dict_word_freq = dict(zip(vectorizer.get_feature_names(), list(doc_term_matrix.sum(0))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ECE01K5OF9r0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "ragged array of words in each document (by index in vocabulary)"
      ]
    },
    {
      "metadata": {
        "id": "NKDN2_x45V44",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def countsToInput(row):\n",
        "  return np.repeat(np.arange(doc_term_matrix.shape[1]),row)\n",
        "  \n",
        "def numWords(row):\n",
        "  return row.sum()\n",
        "\n",
        "N_train = np.apply_along_axis(numWords, axis=1, arr=doc_term_matrix)\n",
        "data_train = []\n",
        "for d in range(doc_term_matrix.shape[0]):\n",
        "  data_train.append(torch.from_numpy(countsToInput(doc_term_matrix[d])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FrATqONaiDBo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Word2vec"
      ]
    },
    {
      "metadata": {
        "id": "41uIgMA1iCEE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec, KeyedVectors\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aLXYF7P7xSEn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ideally, we would do some preprocessing\n",
        "newsgroups_train_preproc = []\n",
        "for document in newsgroups_train.data:\n",
        "    newsgroups_train_preproc.append(document.split())\n",
        "\n",
        "# make the model\n",
        "w2v = Word2Vec(sg=1, negative=5, size=100, window=10, min_count=1, max_vocab_size=None, max_final_vocab=None)\n",
        "# w2v.build_vocab(newsgroups_train_preproc)\n",
        "w2v.build_vocab_from_freq(word_freq = dict_word_freq)\n",
        "# train the model\n",
        "w2v.train(sentences=newsgroups_train_preproc,epochs=10, total_examples=doc_term_matrix.shape[1])\n",
        "# save the model\n",
        "w2v.save(\"sg1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-nNkaKgu7Dsp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ffbc9826-b5ba-4c2b-e9a8-a293b262faab"
      },
      "cell_type": "code",
      "source": [
        "len(set([item for sublist in newsgroups_train_preproc for item in sublist]))"
      ],
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51319"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "metadata": {
        "id": "2EBD-baJ70bC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "489d8e66-b2e2-4c1d-fd8d-53771d9f00ae"
      },
      "cell_type": "code",
      "source": [
        "torch.tensor(w2v.syn1neg).shape"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn1neg` (Attribute will be removed in 4.0.0, use self.trainables.syn1neg instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2441, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "metadata": {
        "id": "eTmRNeXU6Od7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2cd16639-727a-4ec6-eb8c-9a44c549340f"
      },
      "cell_type": "code",
      "source": [
        "len(w2v.wv.vocab)"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2441"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "metadata": {
        "id": "6efYXjKX3mlP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "w2v.save(\"sg_1_M2\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DTX4Rsqf4IVr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "outputId": "d60ba059-983c-4a3e-d682-e307a9c4d096"
      },
      "cell_type": "code",
      "source": [
        "w2v.syn1neg"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `syn1neg` (Attribute will be removed in 4.0.0, use self.trainables.syn1neg instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-3.50045919e-01, -5.76119006e-01,  3.59132916e-01, ...,\n",
              "        -9.80157554e-01,  6.87077761e-01, -1.63887873e-01],\n",
              "       [-3.11047077e-01, -5.07865191e-01,  3.15256298e-01, ...,\n",
              "        -8.64744723e-01,  6.06829166e-01, -1.45936355e-01],\n",
              "       [-2.52017021e-01, -4.25064832e-01, -1.17316574e-01, ...,\n",
              "        -4.85554546e-01,  1.96210504e-01,  2.83722520e-01],\n",
              "       ...,\n",
              "       [-6.67612478e-02, -2.71932453e-01, -1.09181866e-01, ...,\n",
              "        -2.41017595e-01,  1.27573565e-01, -9.47324336e-02],\n",
              "       [ 5.63658366e-04, -8.60928092e-03,  1.27539486e-01, ...,\n",
              "        -3.16302866e-01,  7.16766790e-02,  4.46170047e-02],\n",
              "       [-1.86148956e-01, -3.18686575e-01,  2.00770959e-01, ...,\n",
              "        -5.40914536e-01,  3.77315015e-01, -8.76149833e-02]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "metadata": {
        "id": "Qe0oJvkE21H3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "3fea39ed-f48c-43cf-8298-de9f163c50b1"
      },
      "cell_type": "code",
      "source": [
        "w2v.wv.most_similar(\"university\")"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('books', 0.9081634283065796),\n",
              " ('students', 0.9059314727783203),\n",
              " ('college', 0.9011502265930176),\n",
              " ('standard', 0.8874714374542236),\n",
              " ('page', 0.8783857822418213),\n",
              " ('library', 0.8773259520530701),\n",
              " ('atlas', 0.868262529373169),\n",
              " ('education', 0.8642970323562622),\n",
              " ('works', 0.8636724948883057),\n",
              " ('connection', 0.8621504306793213)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "metadata": {
        "id": "8ASbgnVqGDvU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup for Model"
      ]
    },
    {
      "metadata": {
        "id": "HoGhPn8n4Gok",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# from types import SimpleNamespace\n",
        "\n",
        "\n",
        "# args_dict = {\"batch_size\" : 50, \"epochs\" : 50, \"no_cuda\" : False, \"seed\" : 1, \"log_interval\" : 10}\n",
        "# args = SimpleNamespace(**args_dict)\n",
        "# args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "\n",
        "\n",
        "args_dict = {\"batch_size\" : 10, \"epochs\" : 50, \"no_cuda\" : False, \"seed\" : 1, \"log_interval\" : 100}\n",
        "args = SimpleNamespace(**args_dict)\n",
        "\n",
        "\n",
        "####\n",
        "\n",
        "\n",
        "args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "\n",
        "torch.manual_seed(args.seed)\n",
        "\n",
        "device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if args.cuda else {}\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True,\n",
        "                   transform=transforms.ToTensor()),\n",
        "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.ToTensor()),\n",
        "    batch_size=args.batch_size, shuffle=True, **kwargs)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6E6F6rVgGXnS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Define model"
      ]
    },
    {
      "metadata": {
        "id": "vwZfWV16T97w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, num_docs):\n",
        "        super(VAE, self).__init__()\n",
        "        \n",
        "        vocab_size = doc_term_matrix.shape[1]\n",
        "        wordvec_dim = 100\n",
        "        encoder_hidden = 256\n",
        "        rp_normal_dim = 100\n",
        "        K = 2\n",
        "        self.num_docs = num_docs\n",
        "#         self.word_embedding = nn.Embedding(vocab_size, wordvec_dim) # decoder\n",
        "        self.word_embedding = nn.Embedding.from_pretrained(torch.tensor(w2v.syn1neg), freeze=True)\n",
        "        self.topic_embedding = nn.Embedding(K, wordvec_dim) # decoder\n",
        "        self.lin1 = nn.Linear(vocab_size, encoder_hidden) # encoder\n",
        "        self.mean = nn.Linear(encoder_hidden, rp_normal_dim) # encoder\n",
        "        self.logvar = nn.Linear(encoder_hidden, rp_normal_dim) # encoder\n",
        "        self.lin2 = nn.Linear(rp_normal_dim, K) # decoder \n",
        "        #self.topicslayer = nn.Linear(wordvec_dim, K) # decoder\n",
        "        self.beta = torch.zeros([K, vocab_size], dtype = torch.float32) # decoder\n",
        "        #self.theta = torch.zeros([10, K], dtype = torch.float32)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h1 = F.relu(self.lin1(x))\n",
        "        return self.mean(h1), self.logvar(h1)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return eps.mul(std).add_(mu) # this gives x ~ N(mu, var)\n",
        "\n",
        "      \n",
        "    def decode(self, z):\n",
        "        x = self.lin2(z) \n",
        "        theta = F.softmax(x, dim = 1) # to get theta, dim = batch size x K\n",
        "        #word_dot_topic = self.topicslayer(self.word_embedding.weight) # weights corresp to topic vector\n",
        "        self.beta = F.softmax(torch.mm(self.word_embedding.weight, \n",
        "                                       torch.transpose(self.topic_embedding.weight, 0, 1)), dim = 0) # beta, dim = V x K\n",
        "        log_theta_dot_beta = torch.log(torch.mm(theta, torch.transpose(self.beta, 0, 1))) # dim = batch size x V\n",
        "        #theta_dot_beta = torch.exp(log_theta_dot_beta - torch.logsumexp(log_theta_dot_beta, dim = 0))\n",
        "        ####log_theta_dot_beta_normalized = log_theta_dot_beta - torch.logsumexp(log_theta_dot_beta, dim = 0)\n",
        "        return log_theta_dot_beta ####log_theta_dot_beta_normalized\n",
        "        \n",
        "    def forward(self, doc):\n",
        "        mu, logvar = self.encode(doc)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar, self.topic_embedding.weight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uoGmoqZjaAHr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load training data (separate into batches)"
      ]
    },
    {
      "metadata": {
        "id": "yWSJgB41sicr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# mnist_train_loader = torch.utils.data.DataLoader(\n",
        "#     datasets.MNIST('../data', train=True, download=True,\n",
        "#                    transform=transforms.ToTensor()),\n",
        "#     batch_size=args.batch_size, shuffle=True, **kwargs)\n",
        "# # enumerate(train_loader)\n",
        "\n",
        "train_data = torch.utils.data.TensorDataset(torch.tensor(doc_term_matrix))\n",
        "train_loader = torch.utils.data.DataLoader(train_data,                                            \n",
        "    batch_size = args.batch_size, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dt0_YBz5aQEI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "instantiate model and define functions for training"
      ]
    },
    {
      "metadata": {
        "id": "DO5T6YFkCTIN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "75aaac2a-4d0c-4382-8411-1a8f3dccdb75"
      },
      "cell_type": "code",
      "source": [
        "model = VAE(doc_term_matrix.shape[1]).to(device) \n",
        "      \n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "# optimizer = optim.RMSprop(model.parameters(), lr = 1e-3)\n",
        "\n",
        "# Reconstruction + KL divergence losses summed over all elements and batch\n",
        "def loss_function(data, train_loader, log_theta_dot_beta, x, mu, logvar, t):\n",
        "    BCE = data[0].shape[0] * 1.0 / len(train_loader.dataset) * log_theta_dot_beta.sum()\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "#     K = t.shape[0]\n",
        "#     arccos = []\n",
        "#     for j in range(K):\n",
        "#         for k in range(j, K):\n",
        "#             arccos.append(torch.acos(torch.dot(t[:, j], t[:, k]) /\n",
        "#                                                    (max(t[:, j].norm() * t[:, k].norm(), 1e-5))))\n",
        "#             arccos.append(F.cosine_similarity(t[:, j], t[:, k]))\n",
        "#     arccos = torch.tensor(arccos)\n",
        "#     print(arccos.max())\n",
        "#     zeta = (1 / (K * K)) * arccos.sum()\n",
        "#     nu = torch.zeros(1)\n",
        "#     print(\"zeta: \" + str(zeta) + \"nu: \" + str(nu))\n",
        "#     for a in arccos:\n",
        "#         nu = nu.add((a - zeta).pow(2))\n",
        "#     nu = (1 / (K * K)) * nu\n",
        "#     print(\"BCE: \" + \"{:.2f}\".format(float(BCE)))\n",
        "#     print(\"KLD: \" + \"{:.2f}\".format(float(KLD)))\n",
        "    return - BCE + KLD# - .1 * (zeta - nu)\n",
        "\n",
        "enc_variables = list(model.lin1.parameters()) + list(model.mean.parameters()) +  list(model.logvar.parameters())\n",
        "dec_variables = list(model.word_embedding.parameters()) + list(model.lin2.parameters()) + list(model.topic_embedding.parameters())\n",
        "\n",
        "\n",
        "optim_enc = optim.Adam(enc_variables, lr=1e-3)\n",
        "optim_dec = optim.Adam(dec_variables, lr=1e-3)\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for switch in range(0,2):\n",
        "        if switch == 0:\n",
        "            print(\"updating encoder variables\")\n",
        "            optimizer = optim_enc\n",
        "        else:\n",
        "            print(\"updating decoder variables\")\n",
        "            optimizer = optim_dec\n",
        "    for batch_idx, data in enumerate(train_loader):\n",
        "        #data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        log_theta_beta, mu, logvar, topic_vecs = model(data[0].float())\n",
        "        loss = loss_function(data, train_loader, log_theta_beta, data, mu, logvar, topic_vecs)\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * data[0].shape[0], len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader),\n",
        "                loss.item() / data[0].shape[0]))\n",
        "\n",
        "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
        "          epoch, train_loss / len(train_loader.dataset)))\n",
        "\n",
        "    return train_loss / len(train_loader.dataset)\n",
        "\n",
        "\n",
        "# def test(epoch):\n",
        "#     model.eval()\n",
        "#     test_loss = 0\n",
        "#     with torch.no_grad():\n",
        "#         for i, (data, _) in enumerate(test_loader):\n",
        "#             data = data.to(device)\n",
        "#             recon_batch, mu, logvar = model(data)\n",
        "#             test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
        "#             if i == 0:\n",
        "#                 n = min(data.size(0), 8)\n",
        "#                 comparison = torch.cat([data[:n],\n",
        "#                                       recon_batch.view(args.batch_size, 1, 28, 28)[:n]])\n",
        "# #                 save_image(comparison.cpu(),\n",
        "# #                          'results/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
        "\n",
        "#     test_loss /= len(test_loader.dataset)\n",
        "#     print('====> Test set loss: {:.4f}'.format(test_loss))\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     for epoch in range(1, args.epochs + 1):\n",
        "#         train(epoch)\n",
        "#         test(epoch)\n",
        "#         with torch.no_grad():\n",
        "#             sample = torch.randn(64, 20).to(device)\n",
        "#             sample = model.decode(sample).cpu()\n",
        "#             save_image(sample.view(64, 1, 28, 28),\n",
        "#                        'results/sample_' + str(epoch) + '.png')"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `syn1neg` (Attribute will be removed in 4.0.0, use self.trainables.syn1neg instead).\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "zuF9sAfDGjUE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " train the model"
      ]
    },
    {
      "metadata": {
        "id": "WfzHoXkeDrx7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#model = VAE(doc_term_matrix.shape[1])#.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XY-GsKzb3b_h",
        "colab_type": "code",
        "outputId": "9f43b17f-1696-4b8e-aba2-2da1a10e500e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4267
        }
      },
      "cell_type": "code",
      "source": [
        "losses = []\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    losses.append(train(epoch))\n",
        "#     if epoch > 1:\n",
        "#         if np.abs(losses[epoch-1] - losses[epoch-2]) < 1e-2:\n",
        "#             break\n"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 1 [0/1139 (0%)]\tLoss: 191.855286\n",
            "Train Epoch: 1 [1000/1139 (88%)]\tLoss: 182.653345\n",
            "====> Epoch: 1 Average loss: 186.2171\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 2 [0/1139 (0%)]\tLoss: 181.181042\n",
            "Train Epoch: 2 [1000/1139 (88%)]\tLoss: 177.043335\n",
            "====> Epoch: 2 Average loss: 179.1268\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 3 [0/1139 (0%)]\tLoss: 176.910547\n",
            "Train Epoch: 3 [1000/1139 (88%)]\tLoss: 174.559924\n",
            "====> Epoch: 3 Average loss: 175.8279\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 4 [0/1139 (0%)]\tLoss: 174.318286\n",
            "Train Epoch: 4 [1000/1139 (88%)]\tLoss: 173.061731\n",
            "====> Epoch: 4 Average loss: 173.8243\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 5 [0/1139 (0%)]\tLoss: 172.814014\n",
            "Train Epoch: 5 [1000/1139 (88%)]\tLoss: 171.456128\n",
            "====> Epoch: 5 Average loss: 172.4460\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 6 [0/1139 (0%)]\tLoss: 173.594397\n",
            "Train Epoch: 6 [1000/1139 (88%)]\tLoss: 170.974451\n",
            "====> Epoch: 6 Average loss: 171.4558\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 7 [0/1139 (0%)]\tLoss: 170.755872\n",
            "Train Epoch: 7 [1000/1139 (88%)]\tLoss: 170.134314\n",
            "====> Epoch: 7 Average loss: 170.7333\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 8 [0/1139 (0%)]\tLoss: 170.391101\n",
            "Train Epoch: 8 [1000/1139 (88%)]\tLoss: 169.801416\n",
            "====> Epoch: 8 Average loss: 170.2001\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 9 [0/1139 (0%)]\tLoss: 171.473181\n",
            "Train Epoch: 9 [1000/1139 (88%)]\tLoss: 169.335742\n",
            "====> Epoch: 9 Average loss: 169.8004\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 10 [0/1139 (0%)]\tLoss: 169.197839\n",
            "Train Epoch: 10 [1000/1139 (88%)]\tLoss: 169.257739\n",
            "====> Epoch: 10 Average loss: 169.4941\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 11 [0/1139 (0%)]\tLoss: 168.927136\n",
            "Train Epoch: 11 [1000/1139 (88%)]\tLoss: 168.795618\n",
            "====> Epoch: 11 Average loss: 169.2540\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 12 [0/1139 (0%)]\tLoss: 168.670227\n",
            "Train Epoch: 12 [1000/1139 (88%)]\tLoss: 168.521277\n",
            "====> Epoch: 12 Average loss: 169.0620\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 13 [0/1139 (0%)]\tLoss: 168.682520\n",
            "Train Epoch: 13 [1000/1139 (88%)]\tLoss: 168.508081\n",
            "====> Epoch: 13 Average loss: 168.9064\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 14 [0/1139 (0%)]\tLoss: 168.322095\n",
            "Train Epoch: 14 [1000/1139 (88%)]\tLoss: 170.459741\n",
            "====> Epoch: 14 Average loss: 168.7788\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 15 [0/1139 (0%)]\tLoss: 168.279785\n",
            "Train Epoch: 15 [1000/1139 (88%)]\tLoss: 168.165393\n",
            "====> Epoch: 15 Average loss: 168.6736\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 16 [0/1139 (0%)]\tLoss: 174.474207\n",
            "Train Epoch: 16 [1000/1139 (88%)]\tLoss: 168.359558\n",
            "====> Epoch: 16 Average loss: 168.5864\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 17 [0/1139 (0%)]\tLoss: 168.178430\n",
            "Train Epoch: 17 [1000/1139 (88%)]\tLoss: 167.916296\n",
            "====> Epoch: 17 Average loss: 168.5139\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 18 [0/1139 (0%)]\tLoss: 167.957727\n",
            "Train Epoch: 18 [1000/1139 (88%)]\tLoss: 168.025696\n",
            "====> Epoch: 18 Average loss: 168.4533\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 19 [0/1139 (0%)]\tLoss: 168.107983\n",
            "Train Epoch: 19 [1000/1139 (88%)]\tLoss: 168.127637\n",
            "====> Epoch: 19 Average loss: 168.4021\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 20 [0/1139 (0%)]\tLoss: 168.264978\n",
            "Train Epoch: 20 [1000/1139 (88%)]\tLoss: 167.898572\n",
            "====> Epoch: 20 Average loss: 168.3587\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 21 [0/1139 (0%)]\tLoss: 168.066431\n",
            "Train Epoch: 21 [1000/1139 (88%)]\tLoss: 168.147107\n",
            "====> Epoch: 21 Average loss: 168.3216\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 22 [0/1139 (0%)]\tLoss: 168.180591\n",
            "Train Epoch: 22 [1000/1139 (88%)]\tLoss: 167.949280\n",
            "====> Epoch: 22 Average loss: 168.2895\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 23 [0/1139 (0%)]\tLoss: 167.782568\n",
            "Train Epoch: 23 [1000/1139 (88%)]\tLoss: 167.938770\n",
            "====> Epoch: 23 Average loss: 168.2615\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 24 [0/1139 (0%)]\tLoss: 167.833691\n",
            "Train Epoch: 24 [1000/1139 (88%)]\tLoss: 167.786108\n",
            "====> Epoch: 24 Average loss: 168.2370\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 25 [0/1139 (0%)]\tLoss: 168.274988\n",
            "Train Epoch: 25 [1000/1139 (88%)]\tLoss: 167.979028\n",
            "====> Epoch: 25 Average loss: 168.2155\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 26 [0/1139 (0%)]\tLoss: 167.733643\n",
            "Train Epoch: 26 [1000/1139 (88%)]\tLoss: 167.693970\n",
            "====> Epoch: 26 Average loss: 168.1965\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 27 [0/1139 (0%)]\tLoss: 167.760571\n",
            "Train Epoch: 27 [1000/1139 (88%)]\tLoss: 168.110632\n",
            "====> Epoch: 27 Average loss: 168.1797\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 28 [0/1139 (0%)]\tLoss: 167.823059\n",
            "Train Epoch: 28 [1000/1139 (88%)]\tLoss: 167.643652\n",
            "====> Epoch: 28 Average loss: 168.1648\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 29 [0/1139 (0%)]\tLoss: 167.791931\n",
            "Train Epoch: 29 [1000/1139 (88%)]\tLoss: 168.144897\n",
            "====> Epoch: 29 Average loss: 168.1515\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 30 [0/1139 (0%)]\tLoss: 167.756738\n",
            "Train Epoch: 30 [1000/1139 (88%)]\tLoss: 167.654138\n",
            "====> Epoch: 30 Average loss: 168.1397\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 31 [0/1139 (0%)]\tLoss: 168.004724\n",
            "Train Epoch: 31 [1000/1139 (88%)]\tLoss: 167.617749\n",
            "====> Epoch: 31 Average loss: 168.1293\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 32 [0/1139 (0%)]\tLoss: 167.754736\n",
            "Train Epoch: 32 [1000/1139 (88%)]\tLoss: 167.820007\n",
            "====> Epoch: 32 Average loss: 168.1200\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 33 [0/1139 (0%)]\tLoss: 168.110461\n",
            "Train Epoch: 33 [1000/1139 (88%)]\tLoss: 198.653906\n",
            "====> Epoch: 33 Average loss: 168.1116\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 34 [0/1139 (0%)]\tLoss: 167.493506\n",
            "Train Epoch: 34 [1000/1139 (88%)]\tLoss: 167.574866\n",
            "====> Epoch: 34 Average loss: 168.1043\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 35 [0/1139 (0%)]\tLoss: 167.611194\n",
            "Train Epoch: 35 [1000/1139 (88%)]\tLoss: 167.584229\n",
            "====> Epoch: 35 Average loss: 168.0976\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 36 [0/1139 (0%)]\tLoss: 167.824915\n",
            "Train Epoch: 36 [1000/1139 (88%)]\tLoss: 168.153918\n",
            "====> Epoch: 36 Average loss: 168.0917\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 37 [0/1139 (0%)]\tLoss: 168.581860\n",
            "Train Epoch: 37 [1000/1139 (88%)]\tLoss: 168.062415\n",
            "====> Epoch: 37 Average loss: 168.0863\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 38 [0/1139 (0%)]\tLoss: 167.579285\n",
            "Train Epoch: 38 [1000/1139 (88%)]\tLoss: 169.675269\n",
            "====> Epoch: 38 Average loss: 168.0816\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 39 [0/1139 (0%)]\tLoss: 167.827917\n",
            "Train Epoch: 39 [1000/1139 (88%)]\tLoss: 168.028906\n",
            "====> Epoch: 39 Average loss: 168.0773\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 40 [0/1139 (0%)]\tLoss: 167.952576\n",
            "Train Epoch: 40 [1000/1139 (88%)]\tLoss: 168.248083\n",
            "====> Epoch: 40 Average loss: 168.0733\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 41 [0/1139 (0%)]\tLoss: 167.545190\n",
            "Train Epoch: 41 [1000/1139 (88%)]\tLoss: 167.741553\n",
            "====> Epoch: 41 Average loss: 168.0698\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 42 [0/1139 (0%)]\tLoss: 167.652356\n",
            "Train Epoch: 42 [1000/1139 (88%)]\tLoss: 167.562781\n",
            "====> Epoch: 42 Average loss: 168.0666\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 43 [0/1139 (0%)]\tLoss: 167.629834\n",
            "Train Epoch: 43 [1000/1139 (88%)]\tLoss: 168.011108\n",
            "====> Epoch: 43 Average loss: 168.0637\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 44 [0/1139 (0%)]\tLoss: 169.880042\n",
            "Train Epoch: 44 [1000/1139 (88%)]\tLoss: 169.243152\n",
            "====> Epoch: 44 Average loss: 168.0610\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 45 [0/1139 (0%)]\tLoss: 167.430469\n",
            "Train Epoch: 45 [1000/1139 (88%)]\tLoss: 167.535876\n",
            "====> Epoch: 45 Average loss: 168.0585\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 46 [0/1139 (0%)]\tLoss: 167.487842\n",
            "Train Epoch: 46 [1000/1139 (88%)]\tLoss: 167.577051\n",
            "====> Epoch: 46 Average loss: 168.0562\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 47 [0/1139 (0%)]\tLoss: 169.449878\n",
            "Train Epoch: 47 [1000/1139 (88%)]\tLoss: 167.957495\n",
            "====> Epoch: 47 Average loss: 168.0541\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 48 [0/1139 (0%)]\tLoss: 167.784875\n",
            "Train Epoch: 48 [1000/1139 (88%)]\tLoss: 168.711230\n",
            "====> Epoch: 48 Average loss: 168.0521\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 49 [0/1139 (0%)]\tLoss: 167.486792\n",
            "Train Epoch: 49 [1000/1139 (88%)]\tLoss: 167.563281\n",
            "====> Epoch: 49 Average loss: 168.0503\n",
            "updating encoder variables\n",
            "updating decoder variables\n",
            "Train Epoch: 50 [0/1139 (0%)]\tLoss: 167.565234\n",
            "Train Epoch: 50 [1000/1139 (88%)]\tLoss: 167.601489\n",
            "====> Epoch: 50 Average loss: 168.0485\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GyQ3-xkrR1XX",
        "colab_type": "code",
        "outputId": "dbb5bdb0-fbe4-4053-f061-008021df31a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "cell_type": "code",
      "source": [
        "model.beta\n",
        "_, ind = torch.sort(model.beta, 0)\n",
        "# ind.numpy()[0:50, 0] - ind.numpy()[0:50, 1]\n",
        "print(np.array(vectorizer.get_feature_names())[ind.numpy()][0:25, 0])\n",
        "print(np.array(vectorizer.get_feature_names())[ind.numpy()][0:25, 1])\n",
        "print(np.array(vectorizer.get_feature_names())[ind.numpy()][0:20, 2])\n",
        "print(np.array(vectorizer.get_feature_names())[ind.numpy()][0:20, 3])\n",
        "print(np.array(vectorizer.get_feature_names())[ind.numpy()][0:20, 4])\n",
        "print(np.array(vectorizer.get_feature_names())[ind.numpy()][0:20, 5])\n",
        "# print(np.array(vectorizer.get_feature_names())[ind.numpy()][0:20, 7])\n",
        "# print(np.array(vectorizer.get_feature_names())[ind.numpy()][0:20, 8])\n",
        "# print(np.array(vectorizer.get_feature_names())[ind.numpy()][0:20, 9])\n",
        "# print(np.array(vectorizer.get_feature_names())[ind.numpy()][0:20, 15])\n",
        "# print(np.array(vectorizer.get_feature_names())[ind.numpy()][0:20, 19])"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['activity' 'added' 'agency' 'actual' 'company' 'exist' 'bar' 'created'\n",
            " 'attempt' 'comments' 'better' 'armored' 'doug' 'afford' 'army' 'academic'\n",
            " 'gsfc' 'hardly' 'stolen' 'cold' 'fully' 'dealing' 'criminals' 'ray'\n",
            " 'ignore']\n",
            "['additional' 'charles' 'affair' 'able' 'agents' 'actions' 'capable'\n",
            " 'decade' 'advance' 'applications' 'cash' 'gap' 'automatic' 'act'\n",
            " 'british' 'berkeley' 'bruce' 'deserve' 'finally' 'caught' 'dangerous'\n",
            " 'effects' 'launcher' 'aurora' 'external']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-206-4c2ee78fef38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for axis 1 with size 2"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "-X7Z51K4EDI2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "35b7c245-257f-45fd-cc5f-2036e043706c"
      },
      "cell_type": "code",
      "source": [
        "model.beta\n",
        "torch.sort()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-475590f63d0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: sort() missing 1 required positional arguments: \"input\""
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "-geZP7XKtadI",
        "colab_type": "code",
        "outputId": "559fc1d5-818b-409c-e1e7-b836730f7b64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# a = torch.randn(100, 128)\n",
        "a = torch.tensor([[1,2,3], [4,5,6]]).float()\n",
        "b = torch.tensor([[1,2,3], [4,5,6]]).float()\n",
        "\n",
        "F.cosine_similarity(a, b)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000, 1.0000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "i5N3s6HCGpxy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Get word vectors and topic vectors"
      ]
    },
    {
      "metadata": {
        "id": "SCcYRL2ySugm",
        "colab_type": "code",
        "outputId": "2600d322-2187-4d8c-bef2-6d61360cfe3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "a = torch.tensor([1])\n",
        "a.add(torch.tensor([2]))\n",
        "print(a)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mOdUu6iSGBVP",
        "colab_type": "code",
        "outputId": "3a8f25b8-c968-4794-cebf-06a6afebdde5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "for i in range(0, 2):\n",
        "  print(i)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6dG8db3b3c-y",
        "colab_type": "code",
        "outputId": "542421f7-0775-4485-c8c8-732e2df68091",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "to"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 1.0982, -0.6489,  0.0177,  ...,  0.7344,  0.6163,  0.6307],\n",
              "        [-0.6461,  0.5238, -0.1179,  ..., -1.1260, -0.5322,  0.7694],\n",
              "        [ 1.2182,  0.6254,  0.0470,  ...,  1.6700,  0.4856,  2.6060],\n",
              "        ...,\n",
              "        [ 0.5594,  1.2776,  1.0770,  ...,  0.8158,  1.5054, -0.4085],\n",
              "        [ 1.0393, -0.1039,  0.9977,  ...,  1.5477, -0.1037,  0.0440],\n",
              "        [ 0.7130,  1.8861, -1.6776,  ..., -0.1981,  1.5925, -1.3581]],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "metadata": {
        "id": "1n0TXZhZG9Er",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Get topic distributions"
      ]
    },
    {
      "metadata": {
        "id": "EIvkM_22DhY-",
        "colab_type": "code",
        "outputId": "86746194-5412-421a-f76a-5813328d9663",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "unscaled_topics = torch.mm(model.word_embedding(torch.tensor(np.arange(doc_term_matrix.shape[1]))),\n",
        "         torch.transpose(model.topicslayer.weight, 0, 1))\n",
        "topic_dist = torch.softmax(unscaled_topics, dim = 0)\n",
        "topic_dist.sum(dim = 0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000, 1.0000, 1.0000, 1.0000], grad_fn=<SumBackward1>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "metadata": {
        "id": "bR5eDznAHONV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This one helped us a lot"
      ]
    },
    {
      "metadata": {
        "id": "z16IGTridRPf",
        "colab_type": "code",
        "outputId": "9e684533-0527-4dfc-929b-402285e716ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "cell_type": "code",
      "source": [
        "#model.encode(torch.LongTensor(doc_term_matrix[0]))\n",
        "#input = torch.tensor(doc_term_matrix).float()\n",
        "input = torch.tensor(doc_term_matrix).float()[[0, 1], ]\n",
        "mu, sigma = model.encode(input)\n",
        "z = model.reparameterize(mu, sigma)\n",
        "# model.decode(x, input.shape[0])\n",
        "\n",
        "x = model.fc3(z)\n",
        "theta = F.softmax(x) # to get theta\n",
        "embedding_matrix = model.word_embedding(torch.tensor(np.arange(14)))\n",
        "word_dot_topic = model.fc4(embedding_matrix) # weights corresp to topic vector\n",
        "beta = F.softmax(word_dot_topic)\n",
        "log_theta_dot_beta = torch.log(torch.mm(theta, torch.transpose(beta, 0, 1)))\n",
        "#theta_dot_beta = torch.exp(log_theta_dot_beta - torch.logsumexp(log_theta_dot_beta, dim = 0))\n",
        "log_theta_dot_beta_normalized = log_theta_dot_beta - torch.logsumexp(log_theta_dot_beta, dim = 0)\n",
        "# print(theta.shape)\n",
        "# print(theta)\n",
        "# print(embedding_matrix)\n",
        "# print(word_dot_topic)\n",
        "print(beta.shape)\n",
        "print(beta)\n",
        "print(log_theta_dot_beta)\n",
        "print(torch.exp(log_theta_dot_beta_normalized))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-270-b9bfe4a0b8a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# model.decode(x, input.shape[0])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# to get theta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0membedding_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 518\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'VAE' object has no attribute 'fc3'"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "YPbnTiNpCcaO",
        "colab_type": "code",
        "outputId": "11798aae-8123-4d39-8576-3c00e612beef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "cell_type": "code",
      "source": [
        "#model.encode(torch.LongTensor(doc_term_matrix[0]))\n",
        "#input = torch.tensor(doc_term_matrix).float()\n",
        "input = torch.tensor(doc_term_matrix).float()[[0, 1], ]\n",
        "print(input)\n",
        "mu, sigma = model.encode(input)\n",
        "z = model.reparameterize(mu, sigma)\n",
        "print(z)\n",
        "# model.decode(x, input.shape[0])\n",
        "\n",
        "\n",
        "# x = model.lin2(z)\n",
        "# theta = F.softmax(x) # to get theta\n",
        "# embedding_matrix = model.word_embedding(torch.tensor(np.arange(model.num_docs)))\n",
        "# word_dot_topic = model.topicslayer(embedding_matrix) # weights corresp to topic vector\n",
        "# model.beta = F.softmax(word_dot_topic, dim = 0)\n",
        "# log_theta_dot_beta = torch.log(torch.mm(theta, torch.transpose(model.beta, 0, 1)))\n",
        "# #theta_dot_beta = torch.exp(log_theta_dot_beta - torch.logsumexp(log_theta_dot_beta, dim = 0))\n",
        "# log_theta_dot_beta_normalized = log_theta_dot_beta - torch.logsumexp(log_theta_dot_beta, dim = 0)\n",
        "# print(embedding_matrix.shape) # dim of embedding matrix is 1544 x 100\n",
        "\n",
        "\n",
        "x = model.lin2(z)\n",
        "theta = F.softmax(x, 1) # to get theta\n",
        "print(theta.sum(1))\n",
        "embedding_matrix = model.word_embedding.weight\n",
        "print(model.word_embedding(torch.tensor(np.arange(model.num_docs))).shape)\n",
        "print(embedding_matrix.shape)\n",
        "word_dot_topic = model.topicslayer(embedding_matrix) # weights corresp to topic vector\n",
        "model.beta = F.softmax(word_dot_topic, dim = 0)\n",
        "log_theta_dot_beta = torch.log(torch.mm(theta, torch.transpose(model.beta, 0, 1)))\n",
        "#theta_dot_beta = torch.exp(log_theta_dot_beta - torch.logsumexp(log_theta_dot_beta, dim = 0))\n",
        "log_theta_dot_beta_normalized = log_theta_dot_beta - torch.logsumexp(log_theta_dot_beta, dim = 0)\n",
        "# print(embedding_matrix.shape) # dim of embedding matrix is still 1544 x 100\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "tensor([[-0.3542, -0.9824,  1.6668,  0.2909, -1.7727,  1.6447, -0.0335, -0.3574,\n",
            "         -1.0229,  0.9524,  0.7662, -0.0573,  0.7221, -0.9453,  0.6689, -0.3142,\n",
            "          1.1116, -0.5060, -0.5279,  0.1749,  0.5559, -0.7530, -0.2019, -0.1538,\n",
            "          1.5552],\n",
            "        [ 1.1045,  0.5738, -1.3214,  0.2868,  0.1640, -0.9203,  0.2256, -1.9079,\n",
            "         -0.8485, -0.1582,  0.7142, -0.5238,  0.4466, -0.1109,  0.0060,  0.5935,\n",
            "         -2.4257, -1.1120, -0.1708, -0.0022, -3.3380, -0.6230, -0.6414,  2.1400,\n",
            "          0.5324]], grad_fn=<ThAddBackward>)\n",
            "tensor([1.0000, 1.0000], grad_fn=<SumBackward1>)\n",
            "torch.Size([1544, 100])\n",
            "torch.Size([1544, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Lh2eLudHDncY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "\n",
        "def topic_coherence(beta, M, doc_term_matrix):\n",
        "  K = beta.shape[1] # beta has dim V x K\n",
        "  coherences = np.zeros(K)\n",
        "  for t in range(K):\n",
        "    index = np.argsort(-beta[:, t])[0:M]\n",
        "    cart_prod = product(list(index), list(index))\n",
        "    for ind1, ind2 in cart_prod:\n",
        "      if ind1 == ind2:\n",
        "        pass\n",
        "      else:\n",
        "        d_ind1 = (doc_term_matrix[:, ind1] > 0).sum()\n",
        "        d_ind12 = ((doc_term_matrix[:, ind1] > 0) & (doc_term_matrix[:, ind2] > 0)).sum()\n",
        "        coherences[t] += np.log1p(d_ind12) - np.log(d_ind1)\n",
        "\n",
        "  return coherences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LKM9IxgsLWKT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "35aec09c-9489-4514-82fb-d31e174440ea"
      },
      "cell_type": "code",
      "source": [
        "topic_coherence(model.beta.detach().numpy(), 20, doc_term_matrix)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-989.91967797, -919.98065837])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "metadata": {
        "id": "7BuiupBeNYqZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}